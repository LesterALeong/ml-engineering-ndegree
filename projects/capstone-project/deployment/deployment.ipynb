{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Dog Breed Classifier Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "reference: https://cloud.google.com/blog/products/ai-machine-learning/ai-in-depth-serving-a-pytorch-text-classifier-on-ai-platform-serving-using-custom-online-prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Prepare model and prediction files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "- torch_model.py\n",
    "- model_prediction.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m# Copyright 2020 Google LLC\u001b[39;49;00m\n",
      "\u001b[37m#\u001b[39;49;00m\n",
      "\u001b[37m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;49;00m\n",
      "\u001b[37m# you may not use this file except in compliance with the License.\u001b[39;49;00m\n",
      "\u001b[37m# You may obtain a copy of the License at\u001b[39;49;00m\n",
      "\u001b[37m#\u001b[39;49;00m\n",
      "\u001b[37m#      http://www.apache.org/licenses/LICENSE-2.0\u001b[39;49;00m\n",
      "\u001b[37m#\u001b[39;49;00m\n",
      "\u001b[37m# Unless required by applicable law or agreed to in writing, software\u001b[39;49;00m\n",
      "\u001b[37m# distributed under the License is distributed on an \"AS IS\" BASIS,\u001b[39;49;00m\n",
      "\u001b[37m# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\u001b[39;49;00m\n",
      "\u001b[37m# See the License for the specific language governing permissions and\u001b[39;49;00m\n",
      "\u001b[37m# limitations under the License.\u001b[39;49;00m\n",
      "\n",
      "\u001b[37m# Lint as: python3\u001b[39;49;00m\n",
      "\u001b[33m\"\"\"Bottleneck ResNet v2 with GroupNorm and Weight Standardization.\"\"\"\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mcollections\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m OrderedDict  \u001b[37m# pylint: disable=g-importing-member\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mnn\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnn\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mnn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mfunctional\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mF\u001b[39;49;00m\n",
      "\n",
      "\n",
      "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mStdConv2d\u001b[39;49;00m(nn.Conv2d):\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mforward\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, x):\n",
      "        w = \u001b[36mself\u001b[39;49;00m.weight\n",
      "        v, m = torch.var_mean(w, dim=[\u001b[34m1\u001b[39;49;00m, \u001b[34m2\u001b[39;49;00m, \u001b[34m3\u001b[39;49;00m], keepdim=\u001b[34mTrue\u001b[39;49;00m, unbiased=\u001b[34mFalse\u001b[39;49;00m)\n",
      "        w = (w - m) / torch.sqrt(v + \u001b[34m1e-10\u001b[39;49;00m)\n",
      "        \u001b[34mreturn\u001b[39;49;00m F.conv2d(x, w, \u001b[36mself\u001b[39;49;00m.bias, \u001b[36mself\u001b[39;49;00m.stride, \u001b[36mself\u001b[39;49;00m.padding,\n",
      "                        \u001b[36mself\u001b[39;49;00m.dilation, \u001b[36mself\u001b[39;49;00m.groups)\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mconv3x3\u001b[39;49;00m(cin, cout, stride=\u001b[34m1\u001b[39;49;00m, groups=\u001b[34m1\u001b[39;49;00m, bias=\u001b[34mFalse\u001b[39;49;00m):\n",
      "    \u001b[34mreturn\u001b[39;49;00m StdConv2d(cin, cout, kernel_size=\u001b[34m3\u001b[39;49;00m, stride=stride,\n",
      "                     padding=\u001b[34m1\u001b[39;49;00m, bias=bias, groups=groups)\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mconv1x1\u001b[39;49;00m(cin, cout, stride=\u001b[34m1\u001b[39;49;00m, bias=\u001b[34mFalse\u001b[39;49;00m):\n",
      "    \u001b[34mreturn\u001b[39;49;00m StdConv2d(cin, cout, kernel_size=\u001b[34m1\u001b[39;49;00m, stride=stride,\n",
      "                     padding=\u001b[34m0\u001b[39;49;00m, bias=bias)\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mtf2th\u001b[39;49;00m(conv_weights):\n",
      "    \u001b[33m\"\"\"Possibly convert HWIO to OIHW.\"\"\"\u001b[39;49;00m\n",
      "    \u001b[34mif\u001b[39;49;00m conv_weights.ndim == \u001b[34m4\u001b[39;49;00m:\n",
      "        conv_weights = conv_weights.transpose([\u001b[34m3\u001b[39;49;00m, \u001b[34m2\u001b[39;49;00m, \u001b[34m0\u001b[39;49;00m, \u001b[34m1\u001b[39;49;00m])\n",
      "    \u001b[34mreturn\u001b[39;49;00m torch.from_numpy(conv_weights)\n",
      "\n",
      "\n",
      "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mPreActBottleneck\u001b[39;49;00m(nn.Module):\n",
      "    \u001b[33m\"\"\"Pre-activation (v2) bottleneck block.\u001b[39;49;00m\n",
      "\u001b[33m\u001b[39;49;00m\n",
      "\u001b[33m    Follows the implementation of \"Identity Mappings in Deep Residual Networks\":\u001b[39;49;00m\n",
      "\u001b[33m    https://github.com/KaimingHe/resnet-1k-layers/blob/master/resnet-pre-act.lua\u001b[39;49;00m\n",
      "\u001b[33m\u001b[39;49;00m\n",
      "\u001b[33m    Except it puts the stride on 3x3 conv when available.\u001b[39;49;00m\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\n",
      "\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32m__init__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, cin, cout=\u001b[34mNone\u001b[39;49;00m, cmid=\u001b[34mNone\u001b[39;49;00m, stride=\u001b[34m1\u001b[39;49;00m):\n",
      "        \u001b[36msuper\u001b[39;49;00m().\u001b[32m__init__\u001b[39;49;00m()\n",
      "        cout = cout \u001b[35mor\u001b[39;49;00m cin\n",
      "        cmid = cmid \u001b[35mor\u001b[39;49;00m cout//\u001b[34m4\u001b[39;49;00m\n",
      "\n",
      "        \u001b[36mself\u001b[39;49;00m.gn1 = nn.GroupNorm(\u001b[34m32\u001b[39;49;00m, cin)\n",
      "        \u001b[36mself\u001b[39;49;00m.conv1 = conv1x1(cin, cmid)\n",
      "        \u001b[36mself\u001b[39;49;00m.gn2 = nn.GroupNorm(\u001b[34m32\u001b[39;49;00m, cmid)\n",
      "        \u001b[36mself\u001b[39;49;00m.conv2 = conv3x3(cmid, cmid, stride)  \u001b[37m# Original code has it on conv1!!\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.gn3 = nn.GroupNorm(\u001b[34m32\u001b[39;49;00m, cmid)\n",
      "        \u001b[36mself\u001b[39;49;00m.conv3 = conv1x1(cmid, cout)\n",
      "        \u001b[36mself\u001b[39;49;00m.relu = nn.ReLU(inplace=\u001b[34mTrue\u001b[39;49;00m)\n",
      "\n",
      "        \u001b[34mif\u001b[39;49;00m (stride != \u001b[34m1\u001b[39;49;00m \u001b[35mor\u001b[39;49;00m cin != cout):\n",
      "            \u001b[37m# Projection also with pre-activation according to paper.\u001b[39;49;00m\n",
      "            \u001b[36mself\u001b[39;49;00m.downsample = conv1x1(cin, cout, stride)\n",
      "\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mforward\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, x):\n",
      "        out = \u001b[36mself\u001b[39;49;00m.relu(\u001b[36mself\u001b[39;49;00m.gn1(x))\n",
      "        \n",
      "        \u001b[37m# Residual branch\u001b[39;49;00m\n",
      "        residual = x\n",
      "        \u001b[34mif\u001b[39;49;00m \u001b[36mhasattr\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mdownsample\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m):\n",
      "            residual = \u001b[36mself\u001b[39;49;00m.downsample(out)\n",
      "\n",
      "        \u001b[37m# Unit's branch\u001b[39;49;00m\n",
      "        out = \u001b[36mself\u001b[39;49;00m.conv1(out)\n",
      "        out = \u001b[36mself\u001b[39;49;00m.conv2(\u001b[36mself\u001b[39;49;00m.relu(\u001b[36mself\u001b[39;49;00m.gn2(out)))\n",
      "        out = \u001b[36mself\u001b[39;49;00m.conv3(\u001b[36mself\u001b[39;49;00m.relu(\u001b[36mself\u001b[39;49;00m.gn3(out)))\n",
      "\n",
      "        \u001b[34mreturn\u001b[39;49;00m out + residual\n",
      "\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mload_from\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, weights, prefix=\u001b[33m'\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m):\n",
      "        convname = \u001b[33m'\u001b[39;49;00m\u001b[33mstandardized_conv2d\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "        \u001b[34mwith\u001b[39;49;00m torch.no_grad():\n",
      "            \u001b[36mself\u001b[39;49;00m.conv1.weight.copy_(tf2th(weights[\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mprefix\u001b[33m}\u001b[39;49;00m\u001b[33ma/\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mconvname\u001b[33m}\u001b[39;49;00m\u001b[33m/kernel\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]))\n",
      "            \u001b[36mself\u001b[39;49;00m.conv2.weight.copy_(tf2th(weights[\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mprefix\u001b[33m}\u001b[39;49;00m\u001b[33mb/\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mconvname\u001b[33m}\u001b[39;49;00m\u001b[33m/kernel\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]))\n",
      "            \u001b[36mself\u001b[39;49;00m.conv3.weight.copy_(tf2th(weights[\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mprefix\u001b[33m}\u001b[39;49;00m\u001b[33mc/\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mconvname\u001b[33m}\u001b[39;49;00m\u001b[33m/kernel\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]))\n",
      "            \u001b[36mself\u001b[39;49;00m.gn1.weight.copy_(tf2th(weights[\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mprefix\u001b[33m}\u001b[39;49;00m\u001b[33ma/group_norm/gamma\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]))\n",
      "            \u001b[36mself\u001b[39;49;00m.gn2.weight.copy_(tf2th(weights[\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mprefix\u001b[33m}\u001b[39;49;00m\u001b[33mb/group_norm/gamma\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]))\n",
      "            \u001b[36mself\u001b[39;49;00m.gn3.weight.copy_(tf2th(weights[\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mprefix\u001b[33m}\u001b[39;49;00m\u001b[33mc/group_norm/gamma\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]))\n",
      "            \u001b[36mself\u001b[39;49;00m.gn1.bias.copy_(tf2th(weights[\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mprefix\u001b[33m}\u001b[39;49;00m\u001b[33ma/group_norm/beta\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]))\n",
      "            \u001b[36mself\u001b[39;49;00m.gn2.bias.copy_(tf2th(weights[\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mprefix\u001b[33m}\u001b[39;49;00m\u001b[33mb/group_norm/beta\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]))\n",
      "            \u001b[36mself\u001b[39;49;00m.gn3.bias.copy_(tf2th(weights[\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mprefix\u001b[33m}\u001b[39;49;00m\u001b[33mc/group_norm/beta\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]))\n",
      "        \u001b[34mif\u001b[39;49;00m \u001b[36mhasattr\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mdownsample\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m):\n",
      "            w = weights[\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mprefix\u001b[33m}\u001b[39;49;00m\u001b[33ma/proj/\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mconvname\u001b[33m}\u001b[39;49;00m\u001b[33m/kernel\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\n",
      "            \u001b[36mself\u001b[39;49;00m.downsample.weight.copy_(tf2th(w))\n",
      "\n",
      "\n",
      "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mResNetV2\u001b[39;49;00m(nn.Module):\n",
      "    \u001b[33m\"\"\"Implementation of Pre-activation (v2) ResNet mode.\"\"\"\u001b[39;49;00m\n",
      "\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32m__init__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, block_units, width_factor, head_size=\u001b[34m21843\u001b[39;49;00m, zero_head=\u001b[34mFalse\u001b[39;49;00m):\n",
      "        \u001b[36msuper\u001b[39;49;00m().\u001b[32m__init__\u001b[39;49;00m()\n",
      "        wf = width_factor  \u001b[37m# shortcut 'cause we'll use it a lot.\u001b[39;49;00m\n",
      "\n",
      "        \u001b[37m# The following will be unreadable if we split lines.\u001b[39;49;00m\n",
      "        \u001b[37m# pylint: disable=line-too-long\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m.root = nn.Sequential(OrderedDict([\n",
      "            (\u001b[33m'\u001b[39;49;00m\u001b[33mconv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, StdConv2d(\u001b[34m3\u001b[39;49;00m, \u001b[34m64\u001b[39;49;00m*wf, kernel_size=\u001b[34m7\u001b[39;49;00m, stride=\u001b[34m2\u001b[39;49;00m, padding=\u001b[34m3\u001b[39;49;00m, bias=\u001b[34mFalse\u001b[39;49;00m)),\n",
      "            (\u001b[33m'\u001b[39;49;00m\u001b[33mpad\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, nn.ConstantPad2d(\u001b[34m1\u001b[39;49;00m, \u001b[34m0\u001b[39;49;00m)),\n",
      "            (\u001b[33m'\u001b[39;49;00m\u001b[33mpool\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, nn.MaxPool2d(kernel_size=\u001b[34m3\u001b[39;49;00m, stride=\u001b[34m2\u001b[39;49;00m, padding=\u001b[34m0\u001b[39;49;00m)),\n",
      "            \u001b[37m# The following is subtly not the same!\u001b[39;49;00m\n",
      "            \u001b[37m# ('pool', nn.MaxPool2d(kernel_size=3, stride=2, padding=1)),\u001b[39;49;00m\n",
      "        ]))\n",
      "\n",
      "        \u001b[36mself\u001b[39;49;00m.body = nn.Sequential(OrderedDict([\n",
      "            (\u001b[33m'\u001b[39;49;00m\u001b[33mblock1\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, nn.Sequential(OrderedDict(\n",
      "                [(\u001b[33m'\u001b[39;49;00m\u001b[33munit01\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, PreActBottleneck(cin=\u001b[34m64\u001b[39;49;00m*wf, cout=\u001b[34m256\u001b[39;49;00m*wf, cmid=\u001b[34m64\u001b[39;49;00m*wf))] +\n",
      "                [(\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33munit\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mi\u001b[33m:\u001b[39;49;00m\u001b[33m02d\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, PreActBottleneck(cin=\u001b[34m256\u001b[39;49;00m*wf, cout=\u001b[34m256\u001b[39;49;00m*wf, cmid=\u001b[34m64\u001b[39;49;00m*wf)) \u001b[34mfor\u001b[39;49;00m i \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(\u001b[34m2\u001b[39;49;00m, block_units[\u001b[34m0\u001b[39;49;00m] + \u001b[34m1\u001b[39;49;00m)],\n",
      "            ))),\n",
      "            (\u001b[33m'\u001b[39;49;00m\u001b[33mblock2\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, nn.Sequential(OrderedDict(\n",
      "                [(\u001b[33m'\u001b[39;49;00m\u001b[33munit01\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, PreActBottleneck(cin=\u001b[34m256\u001b[39;49;00m*wf, cout=\u001b[34m512\u001b[39;49;00m*wf, cmid=\u001b[34m128\u001b[39;49;00m*wf, stride=\u001b[34m2\u001b[39;49;00m))] +\n",
      "                [(\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33munit\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mi\u001b[33m:\u001b[39;49;00m\u001b[33m02d\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, PreActBottleneck(cin=\u001b[34m512\u001b[39;49;00m*wf, cout=\u001b[34m512\u001b[39;49;00m*wf, cmid=\u001b[34m128\u001b[39;49;00m*wf)) \u001b[34mfor\u001b[39;49;00m i \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(\u001b[34m2\u001b[39;49;00m, block_units[\u001b[34m1\u001b[39;49;00m] + \u001b[34m1\u001b[39;49;00m)],\n",
      "            ))),\n",
      "            (\u001b[33m'\u001b[39;49;00m\u001b[33mblock3\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, nn.Sequential(OrderedDict(\n",
      "                [(\u001b[33m'\u001b[39;49;00m\u001b[33munit01\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, PreActBottleneck(cin=\u001b[34m512\u001b[39;49;00m*wf, cout=\u001b[34m1024\u001b[39;49;00m*wf, cmid=\u001b[34m256\u001b[39;49;00m*wf, stride=\u001b[34m2\u001b[39;49;00m))] +\n",
      "                [(\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33munit\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mi\u001b[33m:\u001b[39;49;00m\u001b[33m02d\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, PreActBottleneck(cin=\u001b[34m1024\u001b[39;49;00m*wf, cout=\u001b[34m1024\u001b[39;49;00m*wf, cmid=\u001b[34m256\u001b[39;49;00m*wf)) \u001b[34mfor\u001b[39;49;00m i \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(\u001b[34m2\u001b[39;49;00m, block_units[\u001b[34m2\u001b[39;49;00m] + \u001b[34m1\u001b[39;49;00m)],\n",
      "            ))),\n",
      "            (\u001b[33m'\u001b[39;49;00m\u001b[33mblock4\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, nn.Sequential(OrderedDict(\n",
      "                [(\u001b[33m'\u001b[39;49;00m\u001b[33munit01\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, PreActBottleneck(cin=\u001b[34m1024\u001b[39;49;00m*wf, cout=\u001b[34m2048\u001b[39;49;00m*wf, cmid=\u001b[34m512\u001b[39;49;00m*wf, stride=\u001b[34m2\u001b[39;49;00m))] +\n",
      "                [(\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33munit\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mi\u001b[33m:\u001b[39;49;00m\u001b[33m02d\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, PreActBottleneck(cin=\u001b[34m2048\u001b[39;49;00m*wf, cout=\u001b[34m2048\u001b[39;49;00m*wf, cmid=\u001b[34m512\u001b[39;49;00m*wf)) \u001b[34mfor\u001b[39;49;00m i \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(\u001b[34m2\u001b[39;49;00m, block_units[\u001b[34m3\u001b[39;49;00m] + \u001b[34m1\u001b[39;49;00m)],\n",
      "            ))),\n",
      "        ]))\n",
      "        \u001b[37m# pylint: enable=line-too-long\u001b[39;49;00m\n",
      "\n",
      "        \u001b[36mself\u001b[39;49;00m.zero_head = zero_head\n",
      "        \u001b[36mself\u001b[39;49;00m.head = nn.Sequential(OrderedDict([\n",
      "            (\u001b[33m'\u001b[39;49;00m\u001b[33mgn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, nn.GroupNorm(\u001b[34m32\u001b[39;49;00m, \u001b[34m2048\u001b[39;49;00m*wf)),\n",
      "            (\u001b[33m'\u001b[39;49;00m\u001b[33mrelu\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, nn.ReLU(inplace=\u001b[34mTrue\u001b[39;49;00m)),\n",
      "            (\u001b[33m'\u001b[39;49;00m\u001b[33mavg\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, nn.AdaptiveAvgPool2d(output_size=\u001b[34m1\u001b[39;49;00m)),\n",
      "            (\u001b[33m'\u001b[39;49;00m\u001b[33mconv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, nn.Conv2d(\u001b[34m2048\u001b[39;49;00m*wf, head_size, kernel_size=\u001b[34m1\u001b[39;49;00m, bias=\u001b[34mTrue\u001b[39;49;00m)),\n",
      "        ]))\n",
      "\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mforward\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, x):\n",
      "        x = \u001b[36mself\u001b[39;49;00m.head(\u001b[36mself\u001b[39;49;00m.body(\u001b[36mself\u001b[39;49;00m.root(x)))\n",
      "        \u001b[34massert\u001b[39;49;00m x.shape[-\u001b[34m2\u001b[39;49;00m:] == (\u001b[34m1\u001b[39;49;00m, \u001b[34m1\u001b[39;49;00m)  \u001b[37m# We should have no spatial shape left.\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m x[...,\u001b[34m0\u001b[39;49;00m,\u001b[34m0\u001b[39;49;00m]\n",
      "\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mload_from\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, weights, prefix=\u001b[33m'\u001b[39;49;00m\u001b[33mresnet/\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m):\n",
      "        \u001b[34mwith\u001b[39;49;00m torch.no_grad():\n",
      "            \u001b[36mself\u001b[39;49;00m.root.conv.weight.copy_(tf2th(weights[\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mprefix\u001b[33m}\u001b[39;49;00m\u001b[33mroot_block/standardized_conv2d/kernel\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]))  \u001b[37m# pylint: disable=line-too-long\u001b[39;49;00m\n",
      "            \u001b[36mself\u001b[39;49;00m.head.gn.weight.copy_(tf2th(weights[\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mprefix\u001b[33m}\u001b[39;49;00m\u001b[33mgroup_norm/gamma\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]))\n",
      "            \u001b[36mself\u001b[39;49;00m.head.gn.bias.copy_(tf2th(weights[\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mprefix\u001b[33m}\u001b[39;49;00m\u001b[33mgroup_norm/beta\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]))\n",
      "            \u001b[34mif\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.zero_head:\n",
      "                nn.init.zeros_(\u001b[36mself\u001b[39;49;00m.head.conv.weight)\n",
      "                nn.init.zeros_(\u001b[36mself\u001b[39;49;00m.head.conv.bias)\n",
      "            \u001b[34melse\u001b[39;49;00m:\n",
      "                \u001b[36mself\u001b[39;49;00m.head.conv.weight.copy_(tf2th(weights[\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mprefix\u001b[33m}\u001b[39;49;00m\u001b[33mhead/conv2d/kernel\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]))  \u001b[37m# pylint: disable=line-too-long\u001b[39;49;00m\n",
      "                \u001b[36mself\u001b[39;49;00m.head.conv.bias.copy_(tf2th(weights[\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mprefix\u001b[33m}\u001b[39;49;00m\u001b[33mhead/conv2d/bias\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]))\n",
      "\n",
      "        \u001b[34mfor\u001b[39;49;00m bname, block \u001b[35min\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.body.named_children():\n",
      "            \u001b[34mfor\u001b[39;49;00m uname, unit \u001b[35min\u001b[39;49;00m block.named_children():\n",
      "                unit.load_from(weights, prefix=\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mprefix\u001b[33m}\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mbname\u001b[33m}\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m{\u001b[39;49;00muname\u001b[33m}\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n"
     ]
    }
   ],
   "source": [
    "!pygmentize torch_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorchvision\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mmodels\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mmodels\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorchvision\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mtransforms\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mtransforms\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mbit_model\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m ResNetV2\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mPIL\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m Image\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mPIL\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m ImageFile\n",
      "\n",
      "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mDogBreedPrediction\u001b[39;49;00m(\u001b[36mobject\u001b[39;49;00m):\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32m__init__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, model):\n",
      "        \u001b[36msuper\u001b[39;49;00m(DogBreedPrediction, \u001b[36mself\u001b[39;49;00m).\u001b[32m__init__\u001b[39;49;00m()\n",
      "        \u001b[37m# VGG-16 pretrained model\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m._dog_detector = models.vgg16(pretrained=\u001b[34mTrue\u001b[39;49;00m)\n",
      "        \u001b[37m# BiT fine-tuned model\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m._dog_breed_classifier = model\n",
      "        \u001b[37m# https://pytorch.org/hub/pytorch_vision_vgg/\u001b[39;49;00m\n",
      "        \u001b[37m# both models use the same preprocess step\u001b[39;49;00m\n",
      "        \u001b[36mself\u001b[39;49;00m._preprocess = transforms.Compose([\n",
      "            transforms.Resize(\u001b[34m256\u001b[39;49;00m),\n",
      "            transforms.CenterCrop(\u001b[34m224\u001b[39;49;00m),\n",
      "            transforms.ToTensor(),\n",
      "            transforms.Normalize(\n",
      "                mean=[\u001b[34m0.485\u001b[39;49;00m, \u001b[34m0.456\u001b[39;49;00m, \u001b[34m0.406\u001b[39;49;00m],\n",
      "                std=[\u001b[34m0.229\u001b[39;49;00m, \u001b[34m0.224\u001b[39;49;00m, \u001b[34m0.225\u001b[39;49;00m],\n",
      "            ),\n",
      "        ])\n",
      "\n",
      "        \n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32m_detect_dog\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, input_batch):\n",
      "        \u001b[34mwith\u001b[39;49;00m torch.no_grad():\n",
      "            output = \u001b[36mself\u001b[39;49;00m._dog_detector(input_batch)\n",
      "            \n",
      "        output_idx = output.data.numpy().argmax()\n",
      "        \u001b[34mreturn\u001b[39;49;00m \u001b[34m151\u001b[39;49;00m <= output_idx  <= \u001b[34m268\u001b[39;49;00m\n",
      "    \n",
      "    \n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32m_predit_top3_dog_breeds\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, input_batch):\n",
      "        \u001b[34mdef\u001b[39;49;00m \u001b[32mget_class_name\u001b[39;49;00m(classes):\n",
      "            \u001b[34mreturn\u001b[39;49;00m \u001b[36mmap\u001b[39;49;00m(\u001b[34mlambda\u001b[39;49;00m x: class_names[x], classes)\n",
      "\n",
      "        \u001b[34mwith\u001b[39;49;00m torch.no_grad():\n",
      "            output = \u001b[36mself\u001b[39;49;00m._dog_breed_classifier(input_batch)\n",
      "\n",
      "        \u001b[37m# the following code is to get top-3 dog breeds with respective probability\u001b[39;49;00m\n",
      "        softmax = torch.nn.Softmax(dim=\u001b[34m1\u001b[39;49;00m) \u001b[37m# to get probability distribution over all classes\u001b[39;49;00m\n",
      "        softmax_output = softmax(output.data)\n",
      "        top3_pred_values, top3_pred_indices = torch.topk(softmax_output, \u001b[34m3\u001b[39;49;00m)\n",
      "        top3_pred_prob =  np.squeeze(top3_pred_values).numpy()\n",
      "        top3_pred_classes = np.squeeze(top3_pred_indices).numpy()\n",
      "\n",
      "        \u001b[34mreturn\u001b[39;49;00m \u001b[36mlist\u001b[39;49;00m(\u001b[36mzip\u001b[39;49;00m(get_class_name(top3_pred_classes), top3_pred_prob))\n",
      "    \n",
      "    \n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mpredict\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, instances, **kwargs):\n",
      "        ImageFile.LOAD_TRUNCATED_IMAGES = \u001b[34mTrue\u001b[39;49;00m\n",
      "            \n",
      "        input_img = Image.open(instances)\n",
      "        input_tensor = \u001b[36mself\u001b[39;49;00m._preprocess(input_img)\n",
      "        input_batch = input_tensor.unsqueeze(\u001b[34m0\u001b[39;49;00m) \u001b[37m# (224, 224, 3) -> (1, 224, 224, 3)\u001b[39;49;00m\n",
      "        \n",
      "        \u001b[34mif\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m._detect_dog(input_batch):\n",
      "            \u001b[34mreturn\u001b[39;49;00m {\n",
      "                \u001b[33m'\u001b[39;49;00m\u001b[33mdog_detected:\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[34mTrue\u001b[39;49;00m,\n",
      "                \u001b[33m'\u001b[39;49;00m\u001b[33mmessage\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[36mself\u001b[39;49;00m._predit_top3_dog_breeds(input_batch),\n",
      "            }\n",
      "        \u001b[34melse\u001b[39;49;00m:\n",
      "            \u001b[34mreturn\u001b[39;49;00m {\n",
      "                \u001b[33m'\u001b[39;49;00m\u001b[33mdog_detected\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[34mFalse\u001b[39;49;00m,\n",
      "                \u001b[33m'\u001b[39;49;00m\u001b[33mmessage\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33mNo dog is detected, please try another image again!\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "            }\n",
      "    \n",
      "    \u001b[90m@classmethod\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mfrom_path\u001b[39;49;00m(\u001b[36mcls\u001b[39;49;00m, model_dir):\n",
      "        \u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch_model\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mResNetV2\u001b[39;49;00m\n",
      "        model = ResNetV2([\u001b[34m3\u001b[39;49;00m, \u001b[34m4\u001b[39;49;00m, \u001b[34m23\u001b[39;49;00m, \u001b[34m3\u001b[39;49;00m], width_factor=\u001b[34m1\u001b[39;49;00m, head_size=\u001b[34m133\u001b[39;49;00m, zero_head=\u001b[34mTrue\u001b[39;49;00m)\n",
      "        model.load_state_dict(torch.load(\n",
      "            os.path.join(model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mmodel_transfer.pt\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m), \n",
      "            map_location=torch.device(\u001b[33m'\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)))\n",
      "        \u001b[34mreturn\u001b[39;49;00m \u001b[36mcls\u001b[39;49;00m(model)\n"
     ]
    }
   ],
   "source": [
    "!pygmentize model_prediction.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Build a package for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msetuptools\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m setup\n",
      "\n",
      "REQUIRED_PACKAGES = [\u001b[33m'\u001b[39;49;00m\u001b[33mtorch\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mtorchvision\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\n",
      "\n",
      "setup(\n",
      "    name=\u001b[33m'\u001b[39;49;00m\u001b[33mdog_breed_classifier\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "    version=\u001b[33m'\u001b[39;49;00m\u001b[33m0.1\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "    include_package_data=\u001b[34mTrue\u001b[39;49;00m,\n",
      "    scripts=[\u001b[33m'\u001b[39;49;00m\u001b[33mtorch_model.py\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mmodel_prediction.py\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m],\n",
      "    install_requires=REQUIRED_PACKAGES\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "!pygmentize setup.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running sdist\n",
      "running egg_info\n",
      "writing dog_breed_classifier.egg-info/PKG-INFO\n",
      "writing dependency_links to dog_breed_classifier.egg-info/dependency_links.txt\n",
      "writing requirements to dog_breed_classifier.egg-info/requires.txt\n",
      "writing top-level names to dog_breed_classifier.egg-info/top_level.txt\n",
      "reading manifest file 'dog_breed_classifier.egg-info/SOURCES.txt'\n",
      "writing manifest file 'dog_breed_classifier.egg-info/SOURCES.txt'\n",
      "warning: sdist: standard file not found: should have one of README, README.rst, README.txt, README.md\n",
      "\n",
      "running check\n",
      "warning: check: missing required meta-data: url\n",
      "\n",
      "warning: check: missing meta-data: either (author and author_email) or (maintainer and maintainer_email) must be supplied\n",
      "\n",
      "creating dog_breed_classifier-0.1\n",
      "creating dog_breed_classifier-0.1/dog_breed_classifier.egg-info\n",
      "copying files to dog_breed_classifier-0.1...\n",
      "copying model_prediction.py -> dog_breed_classifier-0.1\n",
      "copying setup.py -> dog_breed_classifier-0.1\n",
      "copying torch_model.py -> dog_breed_classifier-0.1\n",
      "copying dog_breed_classifier.egg-info/PKG-INFO -> dog_breed_classifier-0.1/dog_breed_classifier.egg-info\n",
      "copying dog_breed_classifier.egg-info/SOURCES.txt -> dog_breed_classifier-0.1/dog_breed_classifier.egg-info\n",
      "copying dog_breed_classifier.egg-info/dependency_links.txt -> dog_breed_classifier-0.1/dog_breed_classifier.egg-info\n",
      "copying dog_breed_classifier.egg-info/requires.txt -> dog_breed_classifier-0.1/dog_breed_classifier.egg-info\n",
      "copying dog_breed_classifier.egg-info/top_level.txt -> dog_breed_classifier-0.1/dog_breed_classifier.egg-info\n",
      "Writing dog_breed_classifier-0.1/setup.cfg\n",
      "Creating tar archive\n",
      "removing 'dog_breed_classifier-0.1' (and everything under it)\n"
     ]
    }
   ],
   "source": [
    "!python setup.py sdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "BUCKET = 'dog-breed-classifier'\n",
    "PACKAGES_DIR = 'packages'\n",
    "PACKAGE_NAME = 'dog_breed_classifier-0.1.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = 'dog_breed_classifier'\n",
    "MODEL_DIR = 'models'\n",
    "VERSION_NAME = 'v1'\n",
    "RUNTIME_VERSION = '1.13'\n",
    "REGION = 'asia-northeast1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Put the built package to cloud storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://./dist/dog_breed_classifier-0.1.tar.gz [Content-Type=application/x-tar]...\n",
      "/ [1 files][  3.9 KiB/  3.9 KiB]                                                \n",
      "Operation completed over 1 objects/3.9 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp ./dist/{PACKAGE_NAME} gs://{BUCKET}/{PACKAGES_DIR}/{PACKAGE_NAME}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33mWARNING:\u001b[0m Using endpoint [https://ml.googleapis.com/]\n",
      "Created ml engine model [projects/deep-learning-279406/models/dog_breed_classifier].\n"
     ]
    }
   ],
   "source": [
    "!gcloud ai-platform models create {MODEL_NAME} --regions {REGION}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33mWARNING:\u001b[0m The `gcloud ml-engine` commands have been renamed and will soon be removed. Please use `gcloud ai-platform` instead.\n",
      "\u001b[1;33mWARNING:\u001b[0m Using endpoint [https://ml.googleapis.com/]\n",
      "Creating version (this might take a few minutes)......failed.                  \n",
      "\u001b[1;31mERROR:\u001b[0m (gcloud.alpha.ml-engine.versions.create) Create Version failed. Bad model detected with error: Model requires more memory than allowed. Please try to decrease the model size and re-deploy. If you continue to experience errors, please contact support.\n"
     ]
    }
   ],
   "source": [
    "!gcloud alpha ml-engine versions create {VERSION_NAME} --model {MODEL_NAME} \\\n",
    "    --origin=gs://{BUCKET}/{MODEL_DIR}/ \\\n",
    "    --python-version=3.5 \\\n",
    "    --runtime-version={RUNTIME_VERSION} \\\n",
    "    --package-uris=gs://{BUCKET}/{PACKAGES_DIR}/{PACKAGE_NAME} \\\n",
    "    --machine-type=mls1-c4-m2 \\\n",
    "    --prediction-class=model.DogBreedPrediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf22-gpu.2-2.m47",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf22-gpu.2-2:m47"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
