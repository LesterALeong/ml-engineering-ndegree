{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: onnx in /opt/conda/lib/python3.7/site-packages (1.7.0)\n",
      "Requirement already satisfied: onnxruntime in /opt/conda/lib/python3.7/site-packages (1.3.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from onnx) (1.15.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in /opt/conda/lib/python3.7/site-packages (from onnx) (3.7.4.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from onnx) (1.18.1)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.7/site-packages (from onnx) (3.11.4)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from protobuf->onnx) (47.1.1.post20200529)\n"
     ]
    }
   ],
   "source": [
    "!pip install onnx onnxruntime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dog Detection Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_detection_model = torch.load('dog_detection_model.pt', map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV2(\n",
       "  (features): Sequential(\n",
       "    (0): ConvBNReLU(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (12): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (13): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (14): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (15): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (16): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (17): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (18): ConvBNReLU(\n",
       "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=False)\n",
       "    (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog_detection_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input to the model\n",
    "BATCH_SIZE =  1\n",
    "x = torch.randn(BATCH_SIZE, 3, 224, 224, requires_grad=True, device='cpu')\n",
    "output = dog_detection_model(x)\n",
    "\n",
    "# Export the model\n",
    "torch.onnx.export(dog_detection_model,\n",
    "                  x,\n",
    "                  \"dog-detection-model.onnx\",\n",
    "                  export_params=True,\n",
    "                  opset_version=9,\n",
    "                  do_constant_folding=True,\n",
    "                  input_names=['input'],\n",
    "                  output_names=['output']\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'graph torch-jit-export (\\n  %input[FLOAT, 1x3x224x224]\\n) initializers (\\n  %classifier.1.bias[FLOAT, 1000]\\n  %classifier.1.weight[FLOAT, 1000x1280]\\n  %features.0.0.weight[FLOAT, 32x3x3x3]\\n  %features.0.1.bias[FLOAT, 32]\\n  %features.0.1.running_mean[FLOAT, 32]\\n  %features.0.1.running_var[FLOAT, 32]\\n  %features.0.1.weight[FLOAT, 32]\\n  %features.1.conv.0.0.weight[FLOAT, 32x1x3x3]\\n  %features.1.conv.0.1.bias[FLOAT, 32]\\n  %features.1.conv.0.1.running_mean[FLOAT, 32]\\n  %features.1.conv.0.1.running_var[FLOAT, 32]\\n  %features.1.conv.0.1.weight[FLOAT, 32]\\n  %features.1.conv.1.weight[FLOAT, 16x32x1x1]\\n  %features.1.conv.2.bias[FLOAT, 16]\\n  %features.1.conv.2.running_mean[FLOAT, 16]\\n  %features.1.conv.2.running_var[FLOAT, 16]\\n  %features.1.conv.2.weight[FLOAT, 16]\\n  %features.10.conv.0.0.weight[FLOAT, 384x64x1x1]\\n  %features.10.conv.0.1.bias[FLOAT, 384]\\n  %features.10.conv.0.1.running_mean[FLOAT, 384]\\n  %features.10.conv.0.1.running_var[FLOAT, 384]\\n  %features.10.conv.0.1.weight[FLOAT, 384]\\n  %features.10.conv.1.0.weight[FLOAT, 384x1x3x3]\\n  %features.10.conv.1.1.bias[FLOAT, 384]\\n  %features.10.conv.1.1.running_mean[FLOAT, 384]\\n  %features.10.conv.1.1.running_var[FLOAT, 384]\\n  %features.10.conv.1.1.weight[FLOAT, 384]\\n  %features.10.conv.2.weight[FLOAT, 64x384x1x1]\\n  %features.10.conv.3.bias[FLOAT, 64]\\n  %features.10.conv.3.running_mean[FLOAT, 64]\\n  %features.10.conv.3.running_var[FLOAT, 64]\\n  %features.10.conv.3.weight[FLOAT, 64]\\n  %features.11.conv.0.0.weight[FLOAT, 384x64x1x1]\\n  %features.11.conv.0.1.bias[FLOAT, 384]\\n  %features.11.conv.0.1.running_mean[FLOAT, 384]\\n  %features.11.conv.0.1.running_var[FLOAT, 384]\\n  %features.11.conv.0.1.weight[FLOAT, 384]\\n  %features.11.conv.1.0.weight[FLOAT, 384x1x3x3]\\n  %features.11.conv.1.1.bias[FLOAT, 384]\\n  %features.11.conv.1.1.running_mean[FLOAT, 384]\\n  %features.11.conv.1.1.running_var[FLOAT, 384]\\n  %features.11.conv.1.1.weight[FLOAT, 384]\\n  %features.11.conv.2.weight[FLOAT, 96x384x1x1]\\n  %features.11.conv.3.bias[FLOAT, 96]\\n  %features.11.conv.3.running_mean[FLOAT, 96]\\n  %features.11.conv.3.running_var[FLOAT, 96]\\n  %features.11.conv.3.weight[FLOAT, 96]\\n  %features.12.conv.0.0.weight[FLOAT, 576x96x1x1]\\n  %features.12.conv.0.1.bias[FLOAT, 576]\\n  %features.12.conv.0.1.running_mean[FLOAT, 576]\\n  %features.12.conv.0.1.running_var[FLOAT, 576]\\n  %features.12.conv.0.1.weight[FLOAT, 576]\\n  %features.12.conv.1.0.weight[FLOAT, 576x1x3x3]\\n  %features.12.conv.1.1.bias[FLOAT, 576]\\n  %features.12.conv.1.1.running_mean[FLOAT, 576]\\n  %features.12.conv.1.1.running_var[FLOAT, 576]\\n  %features.12.conv.1.1.weight[FLOAT, 576]\\n  %features.12.conv.2.weight[FLOAT, 96x576x1x1]\\n  %features.12.conv.3.bias[FLOAT, 96]\\n  %features.12.conv.3.running_mean[FLOAT, 96]\\n  %features.12.conv.3.running_var[FLOAT, 96]\\n  %features.12.conv.3.weight[FLOAT, 96]\\n  %features.13.conv.0.0.weight[FLOAT, 576x96x1x1]\\n  %features.13.conv.0.1.bias[FLOAT, 576]\\n  %features.13.conv.0.1.running_mean[FLOAT, 576]\\n  %features.13.conv.0.1.running_var[FLOAT, 576]\\n  %features.13.conv.0.1.weight[FLOAT, 576]\\n  %features.13.conv.1.0.weight[FLOAT, 576x1x3x3]\\n  %features.13.conv.1.1.bias[FLOAT, 576]\\n  %features.13.conv.1.1.running_mean[FLOAT, 576]\\n  %features.13.conv.1.1.running_var[FLOAT, 576]\\n  %features.13.conv.1.1.weight[FLOAT, 576]\\n  %features.13.conv.2.weight[FLOAT, 96x576x1x1]\\n  %features.13.conv.3.bias[FLOAT, 96]\\n  %features.13.conv.3.running_mean[FLOAT, 96]\\n  %features.13.conv.3.running_var[FLOAT, 96]\\n  %features.13.conv.3.weight[FLOAT, 96]\\n  %features.14.conv.0.0.weight[FLOAT, 576x96x1x1]\\n  %features.14.conv.0.1.bias[FLOAT, 576]\\n  %features.14.conv.0.1.running_mean[FLOAT, 576]\\n  %features.14.conv.0.1.running_var[FLOAT, 576]\\n  %features.14.conv.0.1.weight[FLOAT, 576]\\n  %features.14.conv.1.0.weight[FLOAT, 576x1x3x3]\\n  %features.14.conv.1.1.bias[FLOAT, 576]\\n  %features.14.conv.1.1.running_mean[FLOAT, 576]\\n  %features.14.conv.1.1.running_var[FLOAT, 576]\\n  %features.14.conv.1.1.weight[FLOAT, 576]\\n  %features.14.conv.2.weight[FLOAT, 160x576x1x1]\\n  %features.14.conv.3.bias[FLOAT, 160]\\n  %features.14.conv.3.running_mean[FLOAT, 160]\\n  %features.14.conv.3.running_var[FLOAT, 160]\\n  %features.14.conv.3.weight[FLOAT, 160]\\n  %features.15.conv.0.0.weight[FLOAT, 960x160x1x1]\\n  %features.15.conv.0.1.bias[FLOAT, 960]\\n  %features.15.conv.0.1.running_mean[FLOAT, 960]\\n  %features.15.conv.0.1.running_var[FLOAT, 960]\\n  %features.15.conv.0.1.weight[FLOAT, 960]\\n  %features.15.conv.1.0.weight[FLOAT, 960x1x3x3]\\n  %features.15.conv.1.1.bias[FLOAT, 960]\\n  %features.15.conv.1.1.running_mean[FLOAT, 960]\\n  %features.15.conv.1.1.running_var[FLOAT, 960]\\n  %features.15.conv.1.1.weight[FLOAT, 960]\\n  %features.15.conv.2.weight[FLOAT, 160x960x1x1]\\n  %features.15.conv.3.bias[FLOAT, 160]\\n  %features.15.conv.3.running_mean[FLOAT, 160]\\n  %features.15.conv.3.running_var[FLOAT, 160]\\n  %features.15.conv.3.weight[FLOAT, 160]\\n  %features.16.conv.0.0.weight[FLOAT, 960x160x1x1]\\n  %features.16.conv.0.1.bias[FLOAT, 960]\\n  %features.16.conv.0.1.running_mean[FLOAT, 960]\\n  %features.16.conv.0.1.running_var[FLOAT, 960]\\n  %features.16.conv.0.1.weight[FLOAT, 960]\\n  %features.16.conv.1.0.weight[FLOAT, 960x1x3x3]\\n  %features.16.conv.1.1.bias[FLOAT, 960]\\n  %features.16.conv.1.1.running_mean[FLOAT, 960]\\n  %features.16.conv.1.1.running_var[FLOAT, 960]\\n  %features.16.conv.1.1.weight[FLOAT, 960]\\n  %features.16.conv.2.weight[FLOAT, 160x960x1x1]\\n  %features.16.conv.3.bias[FLOAT, 160]\\n  %features.16.conv.3.running_mean[FLOAT, 160]\\n  %features.16.conv.3.running_var[FLOAT, 160]\\n  %features.16.conv.3.weight[FLOAT, 160]\\n  %features.17.conv.0.0.weight[FLOAT, 960x160x1x1]\\n  %features.17.conv.0.1.bias[FLOAT, 960]\\n  %features.17.conv.0.1.running_mean[FLOAT, 960]\\n  %features.17.conv.0.1.running_var[FLOAT, 960]\\n  %features.17.conv.0.1.weight[FLOAT, 960]\\n  %features.17.conv.1.0.weight[FLOAT, 960x1x3x3]\\n  %features.17.conv.1.1.bias[FLOAT, 960]\\n  %features.17.conv.1.1.running_mean[FLOAT, 960]\\n  %features.17.conv.1.1.running_var[FLOAT, 960]\\n  %features.17.conv.1.1.weight[FLOAT, 960]\\n  %features.17.conv.2.weight[FLOAT, 320x960x1x1]\\n  %features.17.conv.3.bias[FLOAT, 320]\\n  %features.17.conv.3.running_mean[FLOAT, 320]\\n  %features.17.conv.3.running_var[FLOAT, 320]\\n  %features.17.conv.3.weight[FLOAT, 320]\\n  %features.18.0.weight[FLOAT, 1280x320x1x1]\\n  %features.18.1.bias[FLOAT, 1280]\\n  %features.18.1.running_mean[FLOAT, 1280]\\n  %features.18.1.running_var[FLOAT, 1280]\\n  %features.18.1.weight[FLOAT, 1280]\\n  %features.2.conv.0.0.weight[FLOAT, 96x16x1x1]\\n  %features.2.conv.0.1.bias[FLOAT, 96]\\n  %features.2.conv.0.1.running_mean[FLOAT, 96]\\n  %features.2.conv.0.1.running_var[FLOAT, 96]\\n  %features.2.conv.0.1.weight[FLOAT, 96]\\n  %features.2.conv.1.0.weight[FLOAT, 96x1x3x3]\\n  %features.2.conv.1.1.bias[FLOAT, 96]\\n  %features.2.conv.1.1.running_mean[FLOAT, 96]\\n  %features.2.conv.1.1.running_var[FLOAT, 96]\\n  %features.2.conv.1.1.weight[FLOAT, 96]\\n  %features.2.conv.2.weight[FLOAT, 24x96x1x1]\\n  %features.2.conv.3.bias[FLOAT, 24]\\n  %features.2.conv.3.running_mean[FLOAT, 24]\\n  %features.2.conv.3.running_var[FLOAT, 24]\\n  %features.2.conv.3.weight[FLOAT, 24]\\n  %features.3.conv.0.0.weight[FLOAT, 144x24x1x1]\\n  %features.3.conv.0.1.bias[FLOAT, 144]\\n  %features.3.conv.0.1.running_mean[FLOAT, 144]\\n  %features.3.conv.0.1.running_var[FLOAT, 144]\\n  %features.3.conv.0.1.weight[FLOAT, 144]\\n  %features.3.conv.1.0.weight[FLOAT, 144x1x3x3]\\n  %features.3.conv.1.1.bias[FLOAT, 144]\\n  %features.3.conv.1.1.running_mean[FLOAT, 144]\\n  %features.3.conv.1.1.running_var[FLOAT, 144]\\n  %features.3.conv.1.1.weight[FLOAT, 144]\\n  %features.3.conv.2.weight[FLOAT, 24x144x1x1]\\n  %features.3.conv.3.bias[FLOAT, 24]\\n  %features.3.conv.3.running_mean[FLOAT, 24]\\n  %features.3.conv.3.running_var[FLOAT, 24]\\n  %features.3.conv.3.weight[FLOAT, 24]\\n  %features.4.conv.0.0.weight[FLOAT, 144x24x1x1]\\n  %features.4.conv.0.1.bias[FLOAT, 144]\\n  %features.4.conv.0.1.running_mean[FLOAT, 144]\\n  %features.4.conv.0.1.running_var[FLOAT, 144]\\n  %features.4.conv.0.1.weight[FLOAT, 144]\\n  %features.4.conv.1.0.weight[FLOAT, 144x1x3x3]\\n  %features.4.conv.1.1.bias[FLOAT, 144]\\n  %features.4.conv.1.1.running_mean[FLOAT, 144]\\n  %features.4.conv.1.1.running_var[FLOAT, 144]\\n  %features.4.conv.1.1.weight[FLOAT, 144]\\n  %features.4.conv.2.weight[FLOAT, 32x144x1x1]\\n  %features.4.conv.3.bias[FLOAT, 32]\\n  %features.4.conv.3.running_mean[FLOAT, 32]\\n  %features.4.conv.3.running_var[FLOAT, 32]\\n  %features.4.conv.3.weight[FLOAT, 32]\\n  %features.5.conv.0.0.weight[FLOAT, 192x32x1x1]\\n  %features.5.conv.0.1.bias[FLOAT, 192]\\n  %features.5.conv.0.1.running_mean[FLOAT, 192]\\n  %features.5.conv.0.1.running_var[FLOAT, 192]\\n  %features.5.conv.0.1.weight[FLOAT, 192]\\n  %features.5.conv.1.0.weight[FLOAT, 192x1x3x3]\\n  %features.5.conv.1.1.bias[FLOAT, 192]\\n  %features.5.conv.1.1.running_mean[FLOAT, 192]\\n  %features.5.conv.1.1.running_var[FLOAT, 192]\\n  %features.5.conv.1.1.weight[FLOAT, 192]\\n  %features.5.conv.2.weight[FLOAT, 32x192x1x1]\\n  %features.5.conv.3.bias[FLOAT, 32]\\n  %features.5.conv.3.running_mean[FLOAT, 32]\\n  %features.5.conv.3.running_var[FLOAT, 32]\\n  %features.5.conv.3.weight[FLOAT, 32]\\n  %features.6.conv.0.0.weight[FLOAT, 192x32x1x1]\\n  %features.6.conv.0.1.bias[FLOAT, 192]\\n  %features.6.conv.0.1.running_mean[FLOAT, 192]\\n  %features.6.conv.0.1.running_var[FLOAT, 192]\\n  %features.6.conv.0.1.weight[FLOAT, 192]\\n  %features.6.conv.1.0.weight[FLOAT, 192x1x3x3]\\n  %features.6.conv.1.1.bias[FLOAT, 192]\\n  %features.6.conv.1.1.running_mean[FLOAT, 192]\\n  %features.6.conv.1.1.running_var[FLOAT, 192]\\n  %features.6.conv.1.1.weight[FLOAT, 192]\\n  %features.6.conv.2.weight[FLOAT, 32x192x1x1]\\n  %features.6.conv.3.bias[FLOAT, 32]\\n  %features.6.conv.3.running_mean[FLOAT, 32]\\n  %features.6.conv.3.running_var[FLOAT, 32]\\n  %features.6.conv.3.weight[FLOAT, 32]\\n  %features.7.conv.0.0.weight[FLOAT, 192x32x1x1]\\n  %features.7.conv.0.1.bias[FLOAT, 192]\\n  %features.7.conv.0.1.running_mean[FLOAT, 192]\\n  %features.7.conv.0.1.running_var[FLOAT, 192]\\n  %features.7.conv.0.1.weight[FLOAT, 192]\\n  %features.7.conv.1.0.weight[FLOAT, 192x1x3x3]\\n  %features.7.conv.1.1.bias[FLOAT, 192]\\n  %features.7.conv.1.1.running_mean[FLOAT, 192]\\n  %features.7.conv.1.1.running_var[FLOAT, 192]\\n  %features.7.conv.1.1.weight[FLOAT, 192]\\n  %features.7.conv.2.weight[FLOAT, 64x192x1x1]\\n  %features.7.conv.3.bias[FLOAT, 64]\\n  %features.7.conv.3.running_mean[FLOAT, 64]\\n  %features.7.conv.3.running_var[FLOAT, 64]\\n  %features.7.conv.3.weight[FLOAT, 64]\\n  %features.8.conv.0.0.weight[FLOAT, 384x64x1x1]\\n  %features.8.conv.0.1.bias[FLOAT, 384]\\n  %features.8.conv.0.1.running_mean[FLOAT, 384]\\n  %features.8.conv.0.1.running_var[FLOAT, 384]\\n  %features.8.conv.0.1.weight[FLOAT, 384]\\n  %features.8.conv.1.0.weight[FLOAT, 384x1x3x3]\\n  %features.8.conv.1.1.bias[FLOAT, 384]\\n  %features.8.conv.1.1.running_mean[FLOAT, 384]\\n  %features.8.conv.1.1.running_var[FLOAT, 384]\\n  %features.8.conv.1.1.weight[FLOAT, 384]\\n  %features.8.conv.2.weight[FLOAT, 64x384x1x1]\\n  %features.8.conv.3.bias[FLOAT, 64]\\n  %features.8.conv.3.running_mean[FLOAT, 64]\\n  %features.8.conv.3.running_var[FLOAT, 64]\\n  %features.8.conv.3.weight[FLOAT, 64]\\n  %features.9.conv.0.0.weight[FLOAT, 384x64x1x1]\\n  %features.9.conv.0.1.bias[FLOAT, 384]\\n  %features.9.conv.0.1.running_mean[FLOAT, 384]\\n  %features.9.conv.0.1.running_var[FLOAT, 384]\\n  %features.9.conv.0.1.weight[FLOAT, 384]\\n  %features.9.conv.1.0.weight[FLOAT, 384x1x3x3]\\n  %features.9.conv.1.1.bias[FLOAT, 384]\\n  %features.9.conv.1.1.running_mean[FLOAT, 384]\\n  %features.9.conv.1.1.running_var[FLOAT, 384]\\n  %features.9.conv.1.1.weight[FLOAT, 384]\\n  %features.9.conv.2.weight[FLOAT, 64x384x1x1]\\n  %features.9.conv.3.bias[FLOAT, 64]\\n  %features.9.conv.3.running_mean[FLOAT, 64]\\n  %features.9.conv.3.running_var[FLOAT, 64]\\n  %features.9.conv.3.weight[FLOAT, 64]\\n) {\\n  %315 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%input, %features.0.0.weight)\\n  %316 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%315, %features.0.1.weight, %features.0.1.bias, %features.0.1.running_mean, %features.0.1.running_var)\\n  %317 = Clip[max = 6, min = 0](%316)\\n  %318 = Conv[dilations = [1, 1], group = 32, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%317, %features.1.conv.0.0.weight)\\n  %319 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%318, %features.1.conv.0.1.weight, %features.1.conv.0.1.bias, %features.1.conv.0.1.running_mean, %features.1.conv.0.1.running_var)\\n  %320 = Clip[max = 6, min = 0](%319)\\n  %321 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%320, %features.1.conv.1.weight)\\n  %322 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%321, %features.1.conv.2.weight, %features.1.conv.2.bias, %features.1.conv.2.running_mean, %features.1.conv.2.running_var)\\n  %323 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%322, %features.2.conv.0.0.weight)\\n  %324 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%323, %features.2.conv.0.1.weight, %features.2.conv.0.1.bias, %features.2.conv.0.1.running_mean, %features.2.conv.0.1.running_var)\\n  %325 = Clip[max = 6, min = 0](%324)\\n  %326 = Conv[dilations = [1, 1], group = 96, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%325, %features.2.conv.1.0.weight)\\n  %327 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%326, %features.2.conv.1.1.weight, %features.2.conv.1.1.bias, %features.2.conv.1.1.running_mean, %features.2.conv.1.1.running_var)\\n  %328 = Clip[max = 6, min = 0](%327)\\n  %329 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%328, %features.2.conv.2.weight)\\n  %330 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%329, %features.2.conv.3.weight, %features.2.conv.3.bias, %features.2.conv.3.running_mean, %features.2.conv.3.running_var)\\n  %331 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%330, %features.3.conv.0.0.weight)\\n  %332 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%331, %features.3.conv.0.1.weight, %features.3.conv.0.1.bias, %features.3.conv.0.1.running_mean, %features.3.conv.0.1.running_var)\\n  %333 = Clip[max = 6, min = 0](%332)\\n  %334 = Conv[dilations = [1, 1], group = 144, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%333, %features.3.conv.1.0.weight)\\n  %335 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%334, %features.3.conv.1.1.weight, %features.3.conv.1.1.bias, %features.3.conv.1.1.running_mean, %features.3.conv.1.1.running_var)\\n  %336 = Clip[max = 6, min = 0](%335)\\n  %337 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%336, %features.3.conv.2.weight)\\n  %338 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%337, %features.3.conv.3.weight, %features.3.conv.3.bias, %features.3.conv.3.running_mean, %features.3.conv.3.running_var)\\n  %339 = Add(%330, %338)\\n  %340 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%339, %features.4.conv.0.0.weight)\\n  %341 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%340, %features.4.conv.0.1.weight, %features.4.conv.0.1.bias, %features.4.conv.0.1.running_mean, %features.4.conv.0.1.running_var)\\n  %342 = Clip[max = 6, min = 0](%341)\\n  %343 = Conv[dilations = [1, 1], group = 144, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%342, %features.4.conv.1.0.weight)\\n  %344 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%343, %features.4.conv.1.1.weight, %features.4.conv.1.1.bias, %features.4.conv.1.1.running_mean, %features.4.conv.1.1.running_var)\\n  %345 = Clip[max = 6, min = 0](%344)\\n  %346 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%345, %features.4.conv.2.weight)\\n  %347 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%346, %features.4.conv.3.weight, %features.4.conv.3.bias, %features.4.conv.3.running_mean, %features.4.conv.3.running_var)\\n  %348 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%347, %features.5.conv.0.0.weight)\\n  %349 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%348, %features.5.conv.0.1.weight, %features.5.conv.0.1.bias, %features.5.conv.0.1.running_mean, %features.5.conv.0.1.running_var)\\n  %350 = Clip[max = 6, min = 0](%349)\\n  %351 = Conv[dilations = [1, 1], group = 192, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%350, %features.5.conv.1.0.weight)\\n  %352 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%351, %features.5.conv.1.1.weight, %features.5.conv.1.1.bias, %features.5.conv.1.1.running_mean, %features.5.conv.1.1.running_var)\\n  %353 = Clip[max = 6, min = 0](%352)\\n  %354 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%353, %features.5.conv.2.weight)\\n  %355 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%354, %features.5.conv.3.weight, %features.5.conv.3.bias, %features.5.conv.3.running_mean, %features.5.conv.3.running_var)\\n  %356 = Add(%347, %355)\\n  %357 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%356, %features.6.conv.0.0.weight)\\n  %358 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%357, %features.6.conv.0.1.weight, %features.6.conv.0.1.bias, %features.6.conv.0.1.running_mean, %features.6.conv.0.1.running_var)\\n  %359 = Clip[max = 6, min = 0](%358)\\n  %360 = Conv[dilations = [1, 1], group = 192, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%359, %features.6.conv.1.0.weight)\\n  %361 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%360, %features.6.conv.1.1.weight, %features.6.conv.1.1.bias, %features.6.conv.1.1.running_mean, %features.6.conv.1.1.running_var)\\n  %362 = Clip[max = 6, min = 0](%361)\\n  %363 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%362, %features.6.conv.2.weight)\\n  %364 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%363, %features.6.conv.3.weight, %features.6.conv.3.bias, %features.6.conv.3.running_mean, %features.6.conv.3.running_var)\\n  %365 = Add(%356, %364)\\n  %366 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%365, %features.7.conv.0.0.weight)\\n  %367 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%366, %features.7.conv.0.1.weight, %features.7.conv.0.1.bias, %features.7.conv.0.1.running_mean, %features.7.conv.0.1.running_var)\\n  %368 = Clip[max = 6, min = 0](%367)\\n  %369 = Conv[dilations = [1, 1], group = 192, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%368, %features.7.conv.1.0.weight)\\n  %370 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%369, %features.7.conv.1.1.weight, %features.7.conv.1.1.bias, %features.7.conv.1.1.running_mean, %features.7.conv.1.1.running_var)\\n  %371 = Clip[max = 6, min = 0](%370)\\n  %372 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%371, %features.7.conv.2.weight)\\n  %373 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%372, %features.7.conv.3.weight, %features.7.conv.3.bias, %features.7.conv.3.running_mean, %features.7.conv.3.running_var)\\n  %374 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%373, %features.8.conv.0.0.weight)\\n  %375 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%374, %features.8.conv.0.1.weight, %features.8.conv.0.1.bias, %features.8.conv.0.1.running_mean, %features.8.conv.0.1.running_var)\\n  %376 = Clip[max = 6, min = 0](%375)\\n  %377 = Conv[dilations = [1, 1], group = 384, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%376, %features.8.conv.1.0.weight)\\n  %378 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%377, %features.8.conv.1.1.weight, %features.8.conv.1.1.bias, %features.8.conv.1.1.running_mean, %features.8.conv.1.1.running_var)\\n  %379 = Clip[max = 6, min = 0](%378)\\n  %380 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%379, %features.8.conv.2.weight)\\n  %381 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%380, %features.8.conv.3.weight, %features.8.conv.3.bias, %features.8.conv.3.running_mean, %features.8.conv.3.running_var)\\n  %382 = Add(%373, %381)\\n  %383 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%382, %features.9.conv.0.0.weight)\\n  %384 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%383, %features.9.conv.0.1.weight, %features.9.conv.0.1.bias, %features.9.conv.0.1.running_mean, %features.9.conv.0.1.running_var)\\n  %385 = Clip[max = 6, min = 0](%384)\\n  %386 = Conv[dilations = [1, 1], group = 384, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%385, %features.9.conv.1.0.weight)\\n  %387 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%386, %features.9.conv.1.1.weight, %features.9.conv.1.1.bias, %features.9.conv.1.1.running_mean, %features.9.conv.1.1.running_var)\\n  %388 = Clip[max = 6, min = 0](%387)\\n  %389 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%388, %features.9.conv.2.weight)\\n  %390 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%389, %features.9.conv.3.weight, %features.9.conv.3.bias, %features.9.conv.3.running_mean, %features.9.conv.3.running_var)\\n  %391 = Add(%382, %390)\\n  %392 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%391, %features.10.conv.0.0.weight)\\n  %393 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%392, %features.10.conv.0.1.weight, %features.10.conv.0.1.bias, %features.10.conv.0.1.running_mean, %features.10.conv.0.1.running_var)\\n  %394 = Clip[max = 6, min = 0](%393)\\n  %395 = Conv[dilations = [1, 1], group = 384, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%394, %features.10.conv.1.0.weight)\\n  %396 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%395, %features.10.conv.1.1.weight, %features.10.conv.1.1.bias, %features.10.conv.1.1.running_mean, %features.10.conv.1.1.running_var)\\n  %397 = Clip[max = 6, min = 0](%396)\\n  %398 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%397, %features.10.conv.2.weight)\\n  %399 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%398, %features.10.conv.3.weight, %features.10.conv.3.bias, %features.10.conv.3.running_mean, %features.10.conv.3.running_var)\\n  %400 = Add(%391, %399)\\n  %401 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%400, %features.11.conv.0.0.weight)\\n  %402 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%401, %features.11.conv.0.1.weight, %features.11.conv.0.1.bias, %features.11.conv.0.1.running_mean, %features.11.conv.0.1.running_var)\\n  %403 = Clip[max = 6, min = 0](%402)\\n  %404 = Conv[dilations = [1, 1], group = 384, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%403, %features.11.conv.1.0.weight)\\n  %405 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%404, %features.11.conv.1.1.weight, %features.11.conv.1.1.bias, %features.11.conv.1.1.running_mean, %features.11.conv.1.1.running_var)\\n  %406 = Clip[max = 6, min = 0](%405)\\n  %407 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%406, %features.11.conv.2.weight)\\n  %408 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%407, %features.11.conv.3.weight, %features.11.conv.3.bias, %features.11.conv.3.running_mean, %features.11.conv.3.running_var)\\n  %409 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%408, %features.12.conv.0.0.weight)\\n  %410 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%409, %features.12.conv.0.1.weight, %features.12.conv.0.1.bias, %features.12.conv.0.1.running_mean, %features.12.conv.0.1.running_var)\\n  %411 = Clip[max = 6, min = 0](%410)\\n  %412 = Conv[dilations = [1, 1], group = 576, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%411, %features.12.conv.1.0.weight)\\n  %413 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%412, %features.12.conv.1.1.weight, %features.12.conv.1.1.bias, %features.12.conv.1.1.running_mean, %features.12.conv.1.1.running_var)\\n  %414 = Clip[max = 6, min = 0](%413)\\n  %415 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%414, %features.12.conv.2.weight)\\n  %416 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%415, %features.12.conv.3.weight, %features.12.conv.3.bias, %features.12.conv.3.running_mean, %features.12.conv.3.running_var)\\n  %417 = Add(%408, %416)\\n  %418 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%417, %features.13.conv.0.0.weight)\\n  %419 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%418, %features.13.conv.0.1.weight, %features.13.conv.0.1.bias, %features.13.conv.0.1.running_mean, %features.13.conv.0.1.running_var)\\n  %420 = Clip[max = 6, min = 0](%419)\\n  %421 = Conv[dilations = [1, 1], group = 576, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%420, %features.13.conv.1.0.weight)\\n  %422 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%421, %features.13.conv.1.1.weight, %features.13.conv.1.1.bias, %features.13.conv.1.1.running_mean, %features.13.conv.1.1.running_var)\\n  %423 = Clip[max = 6, min = 0](%422)\\n  %424 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%423, %features.13.conv.2.weight)\\n  %425 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%424, %features.13.conv.3.weight, %features.13.conv.3.bias, %features.13.conv.3.running_mean, %features.13.conv.3.running_var)\\n  %426 = Add(%417, %425)\\n  %427 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%426, %features.14.conv.0.0.weight)\\n  %428 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%427, %features.14.conv.0.1.weight, %features.14.conv.0.1.bias, %features.14.conv.0.1.running_mean, %features.14.conv.0.1.running_var)\\n  %429 = Clip[max = 6, min = 0](%428)\\n  %430 = Conv[dilations = [1, 1], group = 576, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%429, %features.14.conv.1.0.weight)\\n  %431 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%430, %features.14.conv.1.1.weight, %features.14.conv.1.1.bias, %features.14.conv.1.1.running_mean, %features.14.conv.1.1.running_var)\\n  %432 = Clip[max = 6, min = 0](%431)\\n  %433 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%432, %features.14.conv.2.weight)\\n  %434 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%433, %features.14.conv.3.weight, %features.14.conv.3.bias, %features.14.conv.3.running_mean, %features.14.conv.3.running_var)\\n  %435 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%434, %features.15.conv.0.0.weight)\\n  %436 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%435, %features.15.conv.0.1.weight, %features.15.conv.0.1.bias, %features.15.conv.0.1.running_mean, %features.15.conv.0.1.running_var)\\n  %437 = Clip[max = 6, min = 0](%436)\\n  %438 = Conv[dilations = [1, 1], group = 960, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%437, %features.15.conv.1.0.weight)\\n  %439 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%438, %features.15.conv.1.1.weight, %features.15.conv.1.1.bias, %features.15.conv.1.1.running_mean, %features.15.conv.1.1.running_var)\\n  %440 = Clip[max = 6, min = 0](%439)\\n  %441 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%440, %features.15.conv.2.weight)\\n  %442 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%441, %features.15.conv.3.weight, %features.15.conv.3.bias, %features.15.conv.3.running_mean, %features.15.conv.3.running_var)\\n  %443 = Add(%434, %442)\\n  %444 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%443, %features.16.conv.0.0.weight)\\n  %445 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%444, %features.16.conv.0.1.weight, %features.16.conv.0.1.bias, %features.16.conv.0.1.running_mean, %features.16.conv.0.1.running_var)\\n  %446 = Clip[max = 6, min = 0](%445)\\n  %447 = Conv[dilations = [1, 1], group = 960, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%446, %features.16.conv.1.0.weight)\\n  %448 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%447, %features.16.conv.1.1.weight, %features.16.conv.1.1.bias, %features.16.conv.1.1.running_mean, %features.16.conv.1.1.running_var)\\n  %449 = Clip[max = 6, min = 0](%448)\\n  %450 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%449, %features.16.conv.2.weight)\\n  %451 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%450, %features.16.conv.3.weight, %features.16.conv.3.bias, %features.16.conv.3.running_mean, %features.16.conv.3.running_var)\\n  %452 = Add(%443, %451)\\n  %453 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%452, %features.17.conv.0.0.weight)\\n  %454 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%453, %features.17.conv.0.1.weight, %features.17.conv.0.1.bias, %features.17.conv.0.1.running_mean, %features.17.conv.0.1.running_var)\\n  %455 = Clip[max = 6, min = 0](%454)\\n  %456 = Conv[dilations = [1, 1], group = 960, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%455, %features.17.conv.1.0.weight)\\n  %457 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%456, %features.17.conv.1.1.weight, %features.17.conv.1.1.bias, %features.17.conv.1.1.running_mean, %features.17.conv.1.1.running_var)\\n  %458 = Clip[max = 6, min = 0](%457)\\n  %459 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%458, %features.17.conv.2.weight)\\n  %460 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%459, %features.17.conv.3.weight, %features.17.conv.3.bias, %features.17.conv.3.running_mean, %features.17.conv.3.running_var)\\n  %461 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%460, %features.18.0.weight)\\n  %462 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%461, %features.18.1.weight, %features.18.1.bias, %features.18.1.running_mean, %features.18.1.running_var)\\n  %463 = Clip[max = 6, min = 0](%462)\\n  %464 = ReduceMean[axes = [2, 3], keepdims = 0](%463)\\n  %output = Gemm[alpha = 1, beta = 1, transB = 1](%464, %classifier.1.weight, %classifier.1.bias)\\n  return %output\\n}'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import onnx\n",
    "dog_detection_model = onnx.load('dog-detection-model.onnx')\n",
    "onnx.checker.check_model(dog_detection_model)\n",
    "\n",
    "# Print a human readable representation of the graph\n",
    "onnx.helper.printable_graph(dog_detection_model.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dog Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_classification_model = torch.load('dog_classification_model.pt', map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV2(\n",
       "  (features): Sequential(\n",
       "    (0): ConvBNReLU(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (12): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (13): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (14): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (15): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (16): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (17): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (18): ConvBNReLU(\n",
       "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=False)\n",
       "    (1): Linear(in_features=1280, out_features=133, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog_classification_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input to the model\n",
    "BATCH_SIZE =  1\n",
    "x = torch.randn(BATCH_SIZE, 3, 224, 224, requires_grad=True, device='cpu')\n",
    "output = dog_classification_model(x)\n",
    "\n",
    "# Export the model\n",
    "torch.onnx.export(dog_classification_model,\n",
    "                  x,\n",
    "                  \"dog-classification-model.onnx\",\n",
    "                  export_params=True,\n",
    "                  opset_version=9,\n",
    "                  do_constant_folding=True,\n",
    "                  input_names=['input'],\n",
    "                  output_names=['output']\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'graph torch-jit-export (\\n  %input[FLOAT, 1x3x224x224]\\n) initializers (\\n  %classifier.1.bias[FLOAT, 133]\\n  %classifier.1.weight[FLOAT, 133x1280]\\n  %features.0.0.weight[FLOAT, 32x3x3x3]\\n  %features.0.1.bias[FLOAT, 32]\\n  %features.0.1.running_mean[FLOAT, 32]\\n  %features.0.1.running_var[FLOAT, 32]\\n  %features.0.1.weight[FLOAT, 32]\\n  %features.1.conv.0.0.weight[FLOAT, 32x1x3x3]\\n  %features.1.conv.0.1.bias[FLOAT, 32]\\n  %features.1.conv.0.1.running_mean[FLOAT, 32]\\n  %features.1.conv.0.1.running_var[FLOAT, 32]\\n  %features.1.conv.0.1.weight[FLOAT, 32]\\n  %features.1.conv.1.weight[FLOAT, 16x32x1x1]\\n  %features.1.conv.2.bias[FLOAT, 16]\\n  %features.1.conv.2.running_mean[FLOAT, 16]\\n  %features.1.conv.2.running_var[FLOAT, 16]\\n  %features.1.conv.2.weight[FLOAT, 16]\\n  %features.10.conv.0.0.weight[FLOAT, 384x64x1x1]\\n  %features.10.conv.0.1.bias[FLOAT, 384]\\n  %features.10.conv.0.1.running_mean[FLOAT, 384]\\n  %features.10.conv.0.1.running_var[FLOAT, 384]\\n  %features.10.conv.0.1.weight[FLOAT, 384]\\n  %features.10.conv.1.0.weight[FLOAT, 384x1x3x3]\\n  %features.10.conv.1.1.bias[FLOAT, 384]\\n  %features.10.conv.1.1.running_mean[FLOAT, 384]\\n  %features.10.conv.1.1.running_var[FLOAT, 384]\\n  %features.10.conv.1.1.weight[FLOAT, 384]\\n  %features.10.conv.2.weight[FLOAT, 64x384x1x1]\\n  %features.10.conv.3.bias[FLOAT, 64]\\n  %features.10.conv.3.running_mean[FLOAT, 64]\\n  %features.10.conv.3.running_var[FLOAT, 64]\\n  %features.10.conv.3.weight[FLOAT, 64]\\n  %features.11.conv.0.0.weight[FLOAT, 384x64x1x1]\\n  %features.11.conv.0.1.bias[FLOAT, 384]\\n  %features.11.conv.0.1.running_mean[FLOAT, 384]\\n  %features.11.conv.0.1.running_var[FLOAT, 384]\\n  %features.11.conv.0.1.weight[FLOAT, 384]\\n  %features.11.conv.1.0.weight[FLOAT, 384x1x3x3]\\n  %features.11.conv.1.1.bias[FLOAT, 384]\\n  %features.11.conv.1.1.running_mean[FLOAT, 384]\\n  %features.11.conv.1.1.running_var[FLOAT, 384]\\n  %features.11.conv.1.1.weight[FLOAT, 384]\\n  %features.11.conv.2.weight[FLOAT, 96x384x1x1]\\n  %features.11.conv.3.bias[FLOAT, 96]\\n  %features.11.conv.3.running_mean[FLOAT, 96]\\n  %features.11.conv.3.running_var[FLOAT, 96]\\n  %features.11.conv.3.weight[FLOAT, 96]\\n  %features.12.conv.0.0.weight[FLOAT, 576x96x1x1]\\n  %features.12.conv.0.1.bias[FLOAT, 576]\\n  %features.12.conv.0.1.running_mean[FLOAT, 576]\\n  %features.12.conv.0.1.running_var[FLOAT, 576]\\n  %features.12.conv.0.1.weight[FLOAT, 576]\\n  %features.12.conv.1.0.weight[FLOAT, 576x1x3x3]\\n  %features.12.conv.1.1.bias[FLOAT, 576]\\n  %features.12.conv.1.1.running_mean[FLOAT, 576]\\n  %features.12.conv.1.1.running_var[FLOAT, 576]\\n  %features.12.conv.1.1.weight[FLOAT, 576]\\n  %features.12.conv.2.weight[FLOAT, 96x576x1x1]\\n  %features.12.conv.3.bias[FLOAT, 96]\\n  %features.12.conv.3.running_mean[FLOAT, 96]\\n  %features.12.conv.3.running_var[FLOAT, 96]\\n  %features.12.conv.3.weight[FLOAT, 96]\\n  %features.13.conv.0.0.weight[FLOAT, 576x96x1x1]\\n  %features.13.conv.0.1.bias[FLOAT, 576]\\n  %features.13.conv.0.1.running_mean[FLOAT, 576]\\n  %features.13.conv.0.1.running_var[FLOAT, 576]\\n  %features.13.conv.0.1.weight[FLOAT, 576]\\n  %features.13.conv.1.0.weight[FLOAT, 576x1x3x3]\\n  %features.13.conv.1.1.bias[FLOAT, 576]\\n  %features.13.conv.1.1.running_mean[FLOAT, 576]\\n  %features.13.conv.1.1.running_var[FLOAT, 576]\\n  %features.13.conv.1.1.weight[FLOAT, 576]\\n  %features.13.conv.2.weight[FLOAT, 96x576x1x1]\\n  %features.13.conv.3.bias[FLOAT, 96]\\n  %features.13.conv.3.running_mean[FLOAT, 96]\\n  %features.13.conv.3.running_var[FLOAT, 96]\\n  %features.13.conv.3.weight[FLOAT, 96]\\n  %features.14.conv.0.0.weight[FLOAT, 576x96x1x1]\\n  %features.14.conv.0.1.bias[FLOAT, 576]\\n  %features.14.conv.0.1.running_mean[FLOAT, 576]\\n  %features.14.conv.0.1.running_var[FLOAT, 576]\\n  %features.14.conv.0.1.weight[FLOAT, 576]\\n  %features.14.conv.1.0.weight[FLOAT, 576x1x3x3]\\n  %features.14.conv.1.1.bias[FLOAT, 576]\\n  %features.14.conv.1.1.running_mean[FLOAT, 576]\\n  %features.14.conv.1.1.running_var[FLOAT, 576]\\n  %features.14.conv.1.1.weight[FLOAT, 576]\\n  %features.14.conv.2.weight[FLOAT, 160x576x1x1]\\n  %features.14.conv.3.bias[FLOAT, 160]\\n  %features.14.conv.3.running_mean[FLOAT, 160]\\n  %features.14.conv.3.running_var[FLOAT, 160]\\n  %features.14.conv.3.weight[FLOAT, 160]\\n  %features.15.conv.0.0.weight[FLOAT, 960x160x1x1]\\n  %features.15.conv.0.1.bias[FLOAT, 960]\\n  %features.15.conv.0.1.running_mean[FLOAT, 960]\\n  %features.15.conv.0.1.running_var[FLOAT, 960]\\n  %features.15.conv.0.1.weight[FLOAT, 960]\\n  %features.15.conv.1.0.weight[FLOAT, 960x1x3x3]\\n  %features.15.conv.1.1.bias[FLOAT, 960]\\n  %features.15.conv.1.1.running_mean[FLOAT, 960]\\n  %features.15.conv.1.1.running_var[FLOAT, 960]\\n  %features.15.conv.1.1.weight[FLOAT, 960]\\n  %features.15.conv.2.weight[FLOAT, 160x960x1x1]\\n  %features.15.conv.3.bias[FLOAT, 160]\\n  %features.15.conv.3.running_mean[FLOAT, 160]\\n  %features.15.conv.3.running_var[FLOAT, 160]\\n  %features.15.conv.3.weight[FLOAT, 160]\\n  %features.16.conv.0.0.weight[FLOAT, 960x160x1x1]\\n  %features.16.conv.0.1.bias[FLOAT, 960]\\n  %features.16.conv.0.1.running_mean[FLOAT, 960]\\n  %features.16.conv.0.1.running_var[FLOAT, 960]\\n  %features.16.conv.0.1.weight[FLOAT, 960]\\n  %features.16.conv.1.0.weight[FLOAT, 960x1x3x3]\\n  %features.16.conv.1.1.bias[FLOAT, 960]\\n  %features.16.conv.1.1.running_mean[FLOAT, 960]\\n  %features.16.conv.1.1.running_var[FLOAT, 960]\\n  %features.16.conv.1.1.weight[FLOAT, 960]\\n  %features.16.conv.2.weight[FLOAT, 160x960x1x1]\\n  %features.16.conv.3.bias[FLOAT, 160]\\n  %features.16.conv.3.running_mean[FLOAT, 160]\\n  %features.16.conv.3.running_var[FLOAT, 160]\\n  %features.16.conv.3.weight[FLOAT, 160]\\n  %features.17.conv.0.0.weight[FLOAT, 960x160x1x1]\\n  %features.17.conv.0.1.bias[FLOAT, 960]\\n  %features.17.conv.0.1.running_mean[FLOAT, 960]\\n  %features.17.conv.0.1.running_var[FLOAT, 960]\\n  %features.17.conv.0.1.weight[FLOAT, 960]\\n  %features.17.conv.1.0.weight[FLOAT, 960x1x3x3]\\n  %features.17.conv.1.1.bias[FLOAT, 960]\\n  %features.17.conv.1.1.running_mean[FLOAT, 960]\\n  %features.17.conv.1.1.running_var[FLOAT, 960]\\n  %features.17.conv.1.1.weight[FLOAT, 960]\\n  %features.17.conv.2.weight[FLOAT, 320x960x1x1]\\n  %features.17.conv.3.bias[FLOAT, 320]\\n  %features.17.conv.3.running_mean[FLOAT, 320]\\n  %features.17.conv.3.running_var[FLOAT, 320]\\n  %features.17.conv.3.weight[FLOAT, 320]\\n  %features.18.0.weight[FLOAT, 1280x320x1x1]\\n  %features.18.1.bias[FLOAT, 1280]\\n  %features.18.1.running_mean[FLOAT, 1280]\\n  %features.18.1.running_var[FLOAT, 1280]\\n  %features.18.1.weight[FLOAT, 1280]\\n  %features.2.conv.0.0.weight[FLOAT, 96x16x1x1]\\n  %features.2.conv.0.1.bias[FLOAT, 96]\\n  %features.2.conv.0.1.running_mean[FLOAT, 96]\\n  %features.2.conv.0.1.running_var[FLOAT, 96]\\n  %features.2.conv.0.1.weight[FLOAT, 96]\\n  %features.2.conv.1.0.weight[FLOAT, 96x1x3x3]\\n  %features.2.conv.1.1.bias[FLOAT, 96]\\n  %features.2.conv.1.1.running_mean[FLOAT, 96]\\n  %features.2.conv.1.1.running_var[FLOAT, 96]\\n  %features.2.conv.1.1.weight[FLOAT, 96]\\n  %features.2.conv.2.weight[FLOAT, 24x96x1x1]\\n  %features.2.conv.3.bias[FLOAT, 24]\\n  %features.2.conv.3.running_mean[FLOAT, 24]\\n  %features.2.conv.3.running_var[FLOAT, 24]\\n  %features.2.conv.3.weight[FLOAT, 24]\\n  %features.3.conv.0.0.weight[FLOAT, 144x24x1x1]\\n  %features.3.conv.0.1.bias[FLOAT, 144]\\n  %features.3.conv.0.1.running_mean[FLOAT, 144]\\n  %features.3.conv.0.1.running_var[FLOAT, 144]\\n  %features.3.conv.0.1.weight[FLOAT, 144]\\n  %features.3.conv.1.0.weight[FLOAT, 144x1x3x3]\\n  %features.3.conv.1.1.bias[FLOAT, 144]\\n  %features.3.conv.1.1.running_mean[FLOAT, 144]\\n  %features.3.conv.1.1.running_var[FLOAT, 144]\\n  %features.3.conv.1.1.weight[FLOAT, 144]\\n  %features.3.conv.2.weight[FLOAT, 24x144x1x1]\\n  %features.3.conv.3.bias[FLOAT, 24]\\n  %features.3.conv.3.running_mean[FLOAT, 24]\\n  %features.3.conv.3.running_var[FLOAT, 24]\\n  %features.3.conv.3.weight[FLOAT, 24]\\n  %features.4.conv.0.0.weight[FLOAT, 144x24x1x1]\\n  %features.4.conv.0.1.bias[FLOAT, 144]\\n  %features.4.conv.0.1.running_mean[FLOAT, 144]\\n  %features.4.conv.0.1.running_var[FLOAT, 144]\\n  %features.4.conv.0.1.weight[FLOAT, 144]\\n  %features.4.conv.1.0.weight[FLOAT, 144x1x3x3]\\n  %features.4.conv.1.1.bias[FLOAT, 144]\\n  %features.4.conv.1.1.running_mean[FLOAT, 144]\\n  %features.4.conv.1.1.running_var[FLOAT, 144]\\n  %features.4.conv.1.1.weight[FLOAT, 144]\\n  %features.4.conv.2.weight[FLOAT, 32x144x1x1]\\n  %features.4.conv.3.bias[FLOAT, 32]\\n  %features.4.conv.3.running_mean[FLOAT, 32]\\n  %features.4.conv.3.running_var[FLOAT, 32]\\n  %features.4.conv.3.weight[FLOAT, 32]\\n  %features.5.conv.0.0.weight[FLOAT, 192x32x1x1]\\n  %features.5.conv.0.1.bias[FLOAT, 192]\\n  %features.5.conv.0.1.running_mean[FLOAT, 192]\\n  %features.5.conv.0.1.running_var[FLOAT, 192]\\n  %features.5.conv.0.1.weight[FLOAT, 192]\\n  %features.5.conv.1.0.weight[FLOAT, 192x1x3x3]\\n  %features.5.conv.1.1.bias[FLOAT, 192]\\n  %features.5.conv.1.1.running_mean[FLOAT, 192]\\n  %features.5.conv.1.1.running_var[FLOAT, 192]\\n  %features.5.conv.1.1.weight[FLOAT, 192]\\n  %features.5.conv.2.weight[FLOAT, 32x192x1x1]\\n  %features.5.conv.3.bias[FLOAT, 32]\\n  %features.5.conv.3.running_mean[FLOAT, 32]\\n  %features.5.conv.3.running_var[FLOAT, 32]\\n  %features.5.conv.3.weight[FLOAT, 32]\\n  %features.6.conv.0.0.weight[FLOAT, 192x32x1x1]\\n  %features.6.conv.0.1.bias[FLOAT, 192]\\n  %features.6.conv.0.1.running_mean[FLOAT, 192]\\n  %features.6.conv.0.1.running_var[FLOAT, 192]\\n  %features.6.conv.0.1.weight[FLOAT, 192]\\n  %features.6.conv.1.0.weight[FLOAT, 192x1x3x3]\\n  %features.6.conv.1.1.bias[FLOAT, 192]\\n  %features.6.conv.1.1.running_mean[FLOAT, 192]\\n  %features.6.conv.1.1.running_var[FLOAT, 192]\\n  %features.6.conv.1.1.weight[FLOAT, 192]\\n  %features.6.conv.2.weight[FLOAT, 32x192x1x1]\\n  %features.6.conv.3.bias[FLOAT, 32]\\n  %features.6.conv.3.running_mean[FLOAT, 32]\\n  %features.6.conv.3.running_var[FLOAT, 32]\\n  %features.6.conv.3.weight[FLOAT, 32]\\n  %features.7.conv.0.0.weight[FLOAT, 192x32x1x1]\\n  %features.7.conv.0.1.bias[FLOAT, 192]\\n  %features.7.conv.0.1.running_mean[FLOAT, 192]\\n  %features.7.conv.0.1.running_var[FLOAT, 192]\\n  %features.7.conv.0.1.weight[FLOAT, 192]\\n  %features.7.conv.1.0.weight[FLOAT, 192x1x3x3]\\n  %features.7.conv.1.1.bias[FLOAT, 192]\\n  %features.7.conv.1.1.running_mean[FLOAT, 192]\\n  %features.7.conv.1.1.running_var[FLOAT, 192]\\n  %features.7.conv.1.1.weight[FLOAT, 192]\\n  %features.7.conv.2.weight[FLOAT, 64x192x1x1]\\n  %features.7.conv.3.bias[FLOAT, 64]\\n  %features.7.conv.3.running_mean[FLOAT, 64]\\n  %features.7.conv.3.running_var[FLOAT, 64]\\n  %features.7.conv.3.weight[FLOAT, 64]\\n  %features.8.conv.0.0.weight[FLOAT, 384x64x1x1]\\n  %features.8.conv.0.1.bias[FLOAT, 384]\\n  %features.8.conv.0.1.running_mean[FLOAT, 384]\\n  %features.8.conv.0.1.running_var[FLOAT, 384]\\n  %features.8.conv.0.1.weight[FLOAT, 384]\\n  %features.8.conv.1.0.weight[FLOAT, 384x1x3x3]\\n  %features.8.conv.1.1.bias[FLOAT, 384]\\n  %features.8.conv.1.1.running_mean[FLOAT, 384]\\n  %features.8.conv.1.1.running_var[FLOAT, 384]\\n  %features.8.conv.1.1.weight[FLOAT, 384]\\n  %features.8.conv.2.weight[FLOAT, 64x384x1x1]\\n  %features.8.conv.3.bias[FLOAT, 64]\\n  %features.8.conv.3.running_mean[FLOAT, 64]\\n  %features.8.conv.3.running_var[FLOAT, 64]\\n  %features.8.conv.3.weight[FLOAT, 64]\\n  %features.9.conv.0.0.weight[FLOAT, 384x64x1x1]\\n  %features.9.conv.0.1.bias[FLOAT, 384]\\n  %features.9.conv.0.1.running_mean[FLOAT, 384]\\n  %features.9.conv.0.1.running_var[FLOAT, 384]\\n  %features.9.conv.0.1.weight[FLOAT, 384]\\n  %features.9.conv.1.0.weight[FLOAT, 384x1x3x3]\\n  %features.9.conv.1.1.bias[FLOAT, 384]\\n  %features.9.conv.1.1.running_mean[FLOAT, 384]\\n  %features.9.conv.1.1.running_var[FLOAT, 384]\\n  %features.9.conv.1.1.weight[FLOAT, 384]\\n  %features.9.conv.2.weight[FLOAT, 64x384x1x1]\\n  %features.9.conv.3.bias[FLOAT, 64]\\n  %features.9.conv.3.running_mean[FLOAT, 64]\\n  %features.9.conv.3.running_var[FLOAT, 64]\\n  %features.9.conv.3.weight[FLOAT, 64]\\n) {\\n  %315 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%input, %features.0.0.weight)\\n  %316 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%315, %features.0.1.weight, %features.0.1.bias, %features.0.1.running_mean, %features.0.1.running_var)\\n  %317 = Clip[max = 6, min = 0](%316)\\n  %318 = Conv[dilations = [1, 1], group = 32, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%317, %features.1.conv.0.0.weight)\\n  %319 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%318, %features.1.conv.0.1.weight, %features.1.conv.0.1.bias, %features.1.conv.0.1.running_mean, %features.1.conv.0.1.running_var)\\n  %320 = Clip[max = 6, min = 0](%319)\\n  %321 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%320, %features.1.conv.1.weight)\\n  %322 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%321, %features.1.conv.2.weight, %features.1.conv.2.bias, %features.1.conv.2.running_mean, %features.1.conv.2.running_var)\\n  %323 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%322, %features.2.conv.0.0.weight)\\n  %324 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%323, %features.2.conv.0.1.weight, %features.2.conv.0.1.bias, %features.2.conv.0.1.running_mean, %features.2.conv.0.1.running_var)\\n  %325 = Clip[max = 6, min = 0](%324)\\n  %326 = Conv[dilations = [1, 1], group = 96, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%325, %features.2.conv.1.0.weight)\\n  %327 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%326, %features.2.conv.1.1.weight, %features.2.conv.1.1.bias, %features.2.conv.1.1.running_mean, %features.2.conv.1.1.running_var)\\n  %328 = Clip[max = 6, min = 0](%327)\\n  %329 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%328, %features.2.conv.2.weight)\\n  %330 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%329, %features.2.conv.3.weight, %features.2.conv.3.bias, %features.2.conv.3.running_mean, %features.2.conv.3.running_var)\\n  %331 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%330, %features.3.conv.0.0.weight)\\n  %332 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%331, %features.3.conv.0.1.weight, %features.3.conv.0.1.bias, %features.3.conv.0.1.running_mean, %features.3.conv.0.1.running_var)\\n  %333 = Clip[max = 6, min = 0](%332)\\n  %334 = Conv[dilations = [1, 1], group = 144, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%333, %features.3.conv.1.0.weight)\\n  %335 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%334, %features.3.conv.1.1.weight, %features.3.conv.1.1.bias, %features.3.conv.1.1.running_mean, %features.3.conv.1.1.running_var)\\n  %336 = Clip[max = 6, min = 0](%335)\\n  %337 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%336, %features.3.conv.2.weight)\\n  %338 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%337, %features.3.conv.3.weight, %features.3.conv.3.bias, %features.3.conv.3.running_mean, %features.3.conv.3.running_var)\\n  %339 = Add(%330, %338)\\n  %340 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%339, %features.4.conv.0.0.weight)\\n  %341 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%340, %features.4.conv.0.1.weight, %features.4.conv.0.1.bias, %features.4.conv.0.1.running_mean, %features.4.conv.0.1.running_var)\\n  %342 = Clip[max = 6, min = 0](%341)\\n  %343 = Conv[dilations = [1, 1], group = 144, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%342, %features.4.conv.1.0.weight)\\n  %344 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%343, %features.4.conv.1.1.weight, %features.4.conv.1.1.bias, %features.4.conv.1.1.running_mean, %features.4.conv.1.1.running_var)\\n  %345 = Clip[max = 6, min = 0](%344)\\n  %346 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%345, %features.4.conv.2.weight)\\n  %347 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%346, %features.4.conv.3.weight, %features.4.conv.3.bias, %features.4.conv.3.running_mean, %features.4.conv.3.running_var)\\n  %348 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%347, %features.5.conv.0.0.weight)\\n  %349 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%348, %features.5.conv.0.1.weight, %features.5.conv.0.1.bias, %features.5.conv.0.1.running_mean, %features.5.conv.0.1.running_var)\\n  %350 = Clip[max = 6, min = 0](%349)\\n  %351 = Conv[dilations = [1, 1], group = 192, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%350, %features.5.conv.1.0.weight)\\n  %352 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%351, %features.5.conv.1.1.weight, %features.5.conv.1.1.bias, %features.5.conv.1.1.running_mean, %features.5.conv.1.1.running_var)\\n  %353 = Clip[max = 6, min = 0](%352)\\n  %354 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%353, %features.5.conv.2.weight)\\n  %355 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%354, %features.5.conv.3.weight, %features.5.conv.3.bias, %features.5.conv.3.running_mean, %features.5.conv.3.running_var)\\n  %356 = Add(%347, %355)\\n  %357 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%356, %features.6.conv.0.0.weight)\\n  %358 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%357, %features.6.conv.0.1.weight, %features.6.conv.0.1.bias, %features.6.conv.0.1.running_mean, %features.6.conv.0.1.running_var)\\n  %359 = Clip[max = 6, min = 0](%358)\\n  %360 = Conv[dilations = [1, 1], group = 192, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%359, %features.6.conv.1.0.weight)\\n  %361 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%360, %features.6.conv.1.1.weight, %features.6.conv.1.1.bias, %features.6.conv.1.1.running_mean, %features.6.conv.1.1.running_var)\\n  %362 = Clip[max = 6, min = 0](%361)\\n  %363 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%362, %features.6.conv.2.weight)\\n  %364 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%363, %features.6.conv.3.weight, %features.6.conv.3.bias, %features.6.conv.3.running_mean, %features.6.conv.3.running_var)\\n  %365 = Add(%356, %364)\\n  %366 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%365, %features.7.conv.0.0.weight)\\n  %367 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%366, %features.7.conv.0.1.weight, %features.7.conv.0.1.bias, %features.7.conv.0.1.running_mean, %features.7.conv.0.1.running_var)\\n  %368 = Clip[max = 6, min = 0](%367)\\n  %369 = Conv[dilations = [1, 1], group = 192, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%368, %features.7.conv.1.0.weight)\\n  %370 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%369, %features.7.conv.1.1.weight, %features.7.conv.1.1.bias, %features.7.conv.1.1.running_mean, %features.7.conv.1.1.running_var)\\n  %371 = Clip[max = 6, min = 0](%370)\\n  %372 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%371, %features.7.conv.2.weight)\\n  %373 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%372, %features.7.conv.3.weight, %features.7.conv.3.bias, %features.7.conv.3.running_mean, %features.7.conv.3.running_var)\\n  %374 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%373, %features.8.conv.0.0.weight)\\n  %375 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%374, %features.8.conv.0.1.weight, %features.8.conv.0.1.bias, %features.8.conv.0.1.running_mean, %features.8.conv.0.1.running_var)\\n  %376 = Clip[max = 6, min = 0](%375)\\n  %377 = Conv[dilations = [1, 1], group = 384, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%376, %features.8.conv.1.0.weight)\\n  %378 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%377, %features.8.conv.1.1.weight, %features.8.conv.1.1.bias, %features.8.conv.1.1.running_mean, %features.8.conv.1.1.running_var)\\n  %379 = Clip[max = 6, min = 0](%378)\\n  %380 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%379, %features.8.conv.2.weight)\\n  %381 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%380, %features.8.conv.3.weight, %features.8.conv.3.bias, %features.8.conv.3.running_mean, %features.8.conv.3.running_var)\\n  %382 = Add(%373, %381)\\n  %383 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%382, %features.9.conv.0.0.weight)\\n  %384 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%383, %features.9.conv.0.1.weight, %features.9.conv.0.1.bias, %features.9.conv.0.1.running_mean, %features.9.conv.0.1.running_var)\\n  %385 = Clip[max = 6, min = 0](%384)\\n  %386 = Conv[dilations = [1, 1], group = 384, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%385, %features.9.conv.1.0.weight)\\n  %387 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%386, %features.9.conv.1.1.weight, %features.9.conv.1.1.bias, %features.9.conv.1.1.running_mean, %features.9.conv.1.1.running_var)\\n  %388 = Clip[max = 6, min = 0](%387)\\n  %389 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%388, %features.9.conv.2.weight)\\n  %390 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%389, %features.9.conv.3.weight, %features.9.conv.3.bias, %features.9.conv.3.running_mean, %features.9.conv.3.running_var)\\n  %391 = Add(%382, %390)\\n  %392 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%391, %features.10.conv.0.0.weight)\\n  %393 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%392, %features.10.conv.0.1.weight, %features.10.conv.0.1.bias, %features.10.conv.0.1.running_mean, %features.10.conv.0.1.running_var)\\n  %394 = Clip[max = 6, min = 0](%393)\\n  %395 = Conv[dilations = [1, 1], group = 384, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%394, %features.10.conv.1.0.weight)\\n  %396 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%395, %features.10.conv.1.1.weight, %features.10.conv.1.1.bias, %features.10.conv.1.1.running_mean, %features.10.conv.1.1.running_var)\\n  %397 = Clip[max = 6, min = 0](%396)\\n  %398 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%397, %features.10.conv.2.weight)\\n  %399 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%398, %features.10.conv.3.weight, %features.10.conv.3.bias, %features.10.conv.3.running_mean, %features.10.conv.3.running_var)\\n  %400 = Add(%391, %399)\\n  %401 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%400, %features.11.conv.0.0.weight)\\n  %402 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%401, %features.11.conv.0.1.weight, %features.11.conv.0.1.bias, %features.11.conv.0.1.running_mean, %features.11.conv.0.1.running_var)\\n  %403 = Clip[max = 6, min = 0](%402)\\n  %404 = Conv[dilations = [1, 1], group = 384, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%403, %features.11.conv.1.0.weight)\\n  %405 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%404, %features.11.conv.1.1.weight, %features.11.conv.1.1.bias, %features.11.conv.1.1.running_mean, %features.11.conv.1.1.running_var)\\n  %406 = Clip[max = 6, min = 0](%405)\\n  %407 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%406, %features.11.conv.2.weight)\\n  %408 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%407, %features.11.conv.3.weight, %features.11.conv.3.bias, %features.11.conv.3.running_mean, %features.11.conv.3.running_var)\\n  %409 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%408, %features.12.conv.0.0.weight)\\n  %410 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%409, %features.12.conv.0.1.weight, %features.12.conv.0.1.bias, %features.12.conv.0.1.running_mean, %features.12.conv.0.1.running_var)\\n  %411 = Clip[max = 6, min = 0](%410)\\n  %412 = Conv[dilations = [1, 1], group = 576, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%411, %features.12.conv.1.0.weight)\\n  %413 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%412, %features.12.conv.1.1.weight, %features.12.conv.1.1.bias, %features.12.conv.1.1.running_mean, %features.12.conv.1.1.running_var)\\n  %414 = Clip[max = 6, min = 0](%413)\\n  %415 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%414, %features.12.conv.2.weight)\\n  %416 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%415, %features.12.conv.3.weight, %features.12.conv.3.bias, %features.12.conv.3.running_mean, %features.12.conv.3.running_var)\\n  %417 = Add(%408, %416)\\n  %418 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%417, %features.13.conv.0.0.weight)\\n  %419 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%418, %features.13.conv.0.1.weight, %features.13.conv.0.1.bias, %features.13.conv.0.1.running_mean, %features.13.conv.0.1.running_var)\\n  %420 = Clip[max = 6, min = 0](%419)\\n  %421 = Conv[dilations = [1, 1], group = 576, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%420, %features.13.conv.1.0.weight)\\n  %422 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%421, %features.13.conv.1.1.weight, %features.13.conv.1.1.bias, %features.13.conv.1.1.running_mean, %features.13.conv.1.1.running_var)\\n  %423 = Clip[max = 6, min = 0](%422)\\n  %424 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%423, %features.13.conv.2.weight)\\n  %425 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%424, %features.13.conv.3.weight, %features.13.conv.3.bias, %features.13.conv.3.running_mean, %features.13.conv.3.running_var)\\n  %426 = Add(%417, %425)\\n  %427 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%426, %features.14.conv.0.0.weight)\\n  %428 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%427, %features.14.conv.0.1.weight, %features.14.conv.0.1.bias, %features.14.conv.0.1.running_mean, %features.14.conv.0.1.running_var)\\n  %429 = Clip[max = 6, min = 0](%428)\\n  %430 = Conv[dilations = [1, 1], group = 576, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [2, 2]](%429, %features.14.conv.1.0.weight)\\n  %431 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%430, %features.14.conv.1.1.weight, %features.14.conv.1.1.bias, %features.14.conv.1.1.running_mean, %features.14.conv.1.1.running_var)\\n  %432 = Clip[max = 6, min = 0](%431)\\n  %433 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%432, %features.14.conv.2.weight)\\n  %434 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%433, %features.14.conv.3.weight, %features.14.conv.3.bias, %features.14.conv.3.running_mean, %features.14.conv.3.running_var)\\n  %435 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%434, %features.15.conv.0.0.weight)\\n  %436 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%435, %features.15.conv.0.1.weight, %features.15.conv.0.1.bias, %features.15.conv.0.1.running_mean, %features.15.conv.0.1.running_var)\\n  %437 = Clip[max = 6, min = 0](%436)\\n  %438 = Conv[dilations = [1, 1], group = 960, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%437, %features.15.conv.1.0.weight)\\n  %439 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%438, %features.15.conv.1.1.weight, %features.15.conv.1.1.bias, %features.15.conv.1.1.running_mean, %features.15.conv.1.1.running_var)\\n  %440 = Clip[max = 6, min = 0](%439)\\n  %441 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%440, %features.15.conv.2.weight)\\n  %442 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%441, %features.15.conv.3.weight, %features.15.conv.3.bias, %features.15.conv.3.running_mean, %features.15.conv.3.running_var)\\n  %443 = Add(%434, %442)\\n  %444 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%443, %features.16.conv.0.0.weight)\\n  %445 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%444, %features.16.conv.0.1.weight, %features.16.conv.0.1.bias, %features.16.conv.0.1.running_mean, %features.16.conv.0.1.running_var)\\n  %446 = Clip[max = 6, min = 0](%445)\\n  %447 = Conv[dilations = [1, 1], group = 960, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%446, %features.16.conv.1.0.weight)\\n  %448 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%447, %features.16.conv.1.1.weight, %features.16.conv.1.1.bias, %features.16.conv.1.1.running_mean, %features.16.conv.1.1.running_var)\\n  %449 = Clip[max = 6, min = 0](%448)\\n  %450 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%449, %features.16.conv.2.weight)\\n  %451 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%450, %features.16.conv.3.weight, %features.16.conv.3.bias, %features.16.conv.3.running_mean, %features.16.conv.3.running_var)\\n  %452 = Add(%443, %451)\\n  %453 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%452, %features.17.conv.0.0.weight)\\n  %454 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%453, %features.17.conv.0.1.weight, %features.17.conv.0.1.bias, %features.17.conv.0.1.running_mean, %features.17.conv.0.1.running_var)\\n  %455 = Clip[max = 6, min = 0](%454)\\n  %456 = Conv[dilations = [1, 1], group = 960, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%455, %features.17.conv.1.0.weight)\\n  %457 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%456, %features.17.conv.1.1.weight, %features.17.conv.1.1.bias, %features.17.conv.1.1.running_mean, %features.17.conv.1.1.running_var)\\n  %458 = Clip[max = 6, min = 0](%457)\\n  %459 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%458, %features.17.conv.2.weight)\\n  %460 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%459, %features.17.conv.3.weight, %features.17.conv.3.bias, %features.17.conv.3.running_mean, %features.17.conv.3.running_var)\\n  %461 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%460, %features.18.0.weight)\\n  %462 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 0.899999976158142](%461, %features.18.1.weight, %features.18.1.bias, %features.18.1.running_mean, %features.18.1.running_var)\\n  %463 = Clip[max = 6, min = 0](%462)\\n  %464 = ReduceMean[axes = [2, 3], keepdims = 0](%463)\\n  %output = Gemm[alpha = 1, beta = 1, transB = 1](%464, %classifier.1.weight, %classifier.1.bias)\\n  return %output\\n}'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import onnx\n",
    "dog_classification_model = onnx.load('dog-classification-model.onnx')\n",
    "onnx.checker.check_model(dog_classification_model)\n",
    "\n",
    "# Print a human readable representation of the graph\n",
    "onnx.helper.printable_graph(dog_classification_model.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m49",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m49"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
