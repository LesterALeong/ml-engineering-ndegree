{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Dog Breed Classifier v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "- Save the MobileNet v2 pretrained model for dog detection\n",
    "- Try to replace the Google BiT model with MobileNet v2 since the model size of the Google BiT model is too big(~150MB) while MobileNet' is about 14MB "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchsummary in /opt/conda/lib/python3.7/site-packages (1.5.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch-lr-finder in /opt/conda/lib/python3.7/site-packages (0.1.5)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch-lr-finder) (1.18.1)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from torch-lr-finder) (3.2.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from torch-lr-finder) (4.46.1)\n",
      "Requirement already satisfied: torch>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from torch-lr-finder) (1.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->torch-lr-finder) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->torch-lr-finder) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->torch-lr-finder) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->torch-lr-finder) (0.10.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.1->matplotlib->torch-lr-finder) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch-lr-finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from PIL import ImageFile\n",
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "from torch_lr_finder import LRFinder\n",
    "from torch.optim.lr_scheduler import OneCycleLR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Import Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 8351 total dog images.\n"
     ]
    }
   ],
   "source": [
    "# load filenames for dog images\n",
    "dog_files = np.array(glob(\"../dogImages/*/*/*\"))\n",
    "\n",
    "# print number of images\n",
    "print('There are %d total dog images.' % len(dog_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder('../dogImages/train', transform=preprocess)\n",
    "valid_dataset = datasets.ImageFolder('../dogImages/valid', transform=preprocess)\n",
    "test_dataset = datasets.ImageFolder('../dogImages/test', transform=preprocess)\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "train_dataset_batch = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    ")\n",
    "valid_dataset_batch = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "test_dataset_batch = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "loaders_transfer = {\n",
    "    'train': train_dataset_batch,\n",
    "    'valid': valid_dataset_batch,\n",
    "    'test': test_dataset_batch,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dog Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_detection = models.mobilenet_v2(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV2(\n",
       "  (features): Sequential(\n",
       "    (0): ConvBNReLU(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (12): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (13): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (14): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (15): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (16): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (17): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (18): ConvBNReLU(\n",
       "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=False)\n",
       "    (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_detection, 'dog_detection_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_detection = torch.load('dog_detection_model.pt', map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "def imagenet_pretrained_model_predict(model, preprocess, img_path):\n",
    "    '''\n",
    "    Use a pre-trained model to obtain index corresponding to\n",
    "    predicted ImageNet class for image at specified path\n",
    "    \n",
    "    Args:\n",
    "        img_path: path to an image\n",
    "        \n",
    "    Returns:\n",
    "        index corresponding to pretrained model's prediction\n",
    "    '''\n",
    "    model.eval()\n",
    "    input_img = Image.open(img_path)\n",
    "    \n",
    "    input_tensor = preprocess(input_img)\n",
    "    input_batch = input_tensor.unsqueeze(0)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(input_batch)\n",
    "        \n",
    "    return output.data.numpy().argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dog_detector(model, preprocess, img_path):\n",
    "    result = imagenet_pretrained_model_predict(model, preprocess, img_path)\n",
    "    return 151 <= result <= 268"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0\n",
    "np.random.seed(SEED) # for reproducibility\n",
    "\n",
    "num_choice = 500\n",
    "choices = np.random.choice(len(dog_files), num_choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What percentage in dog_files are successfully detected a dog face?: 0.984\n"
     ]
    }
   ],
   "source": [
    "dog_files_dog_detector_results = [dog_detector(model_detection, preprocess, dog_files[choice]) for choice in choices]\n",
    "print(f'What percentage in dog_files are successfully detected a dog face?: {sum(dog_files_dog_detector_results) / num_choice}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dog Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "model_transfer = models.mobilenet_v2(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV2(\n",
       "  (features): Sequential(\n",
       "    (0): ConvBNReLU(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (12): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (13): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (14): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (15): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (16): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (17): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (18): ConvBNReLU(\n",
       "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=False)\n",
       "    (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "Collapsed": "false",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV2(\n",
       "  (features): Sequential(\n",
       "    (0): ConvBNReLU(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (12): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (13): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (14): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (15): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (16): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (17): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (18): ConvBNReLU(\n",
       "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=1280, out_features=133, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace the last fully-connected layer\n",
    "for param in model_transfer.parameters():\n",
    "    param.requires_grad = False\n",
    "    # Parameters of newly constructed modules have requires_grad=True by default\n",
    "\n",
    "model_transfer.classifier[0] = nn.Dropout(p=0.5, inplace=False)\n",
    "model_transfer.classifier[1] = nn.Linear(1280, 133)\n",
    "\n",
    "model_transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# check if CUDA is available\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(use_cuda)\n",
    "\n",
    "if use_cuda:\n",
    "    model_transfer = model_transfer.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "SEED = 0\n",
    "np.random.seed(SEED) # for reproducibility\n",
    "\n",
    "# https://pytorch.org/docs/stable/notes/randomness.html\n",
    "# enable reproducibility in PyTorch\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "criterion_transfer = nn.CrossEntropyLoss()\n",
    "optimizer_transfer = torch.optim.SGD(model_transfer.parameters(), lr=1e-7, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c7d8e1b223147b9bcdc80f1bc4a0e8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early, the loss has diverged\n",
      "\n",
      "Learning rate search finished. See the graph with {finder_name}.plot()\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr_finder = LRFinder(model_transfer, optimizer_transfer, criterion_transfer, device='cuda' if use_cuda else 'cpu')\n",
    "lr_finder.range_test(loaders_transfer['train'], end_lr=100, num_iter=100)\n",
    "lr_finder.plot() # to inspect the loss-learning rate graph\n",
    "lr_finder.reset() # to reset the model and optimizer to their initial state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#from PIL import ImageFile\n",
    "#ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "def train(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path):\n",
    "    \"\"\"returns trained model\"\"\"\n",
    "    # initialize tracker for minimum validation loss\n",
    "    valid_loss_min = np.Inf\n",
    "    early_stopping_patience = 5\n",
    "        \n",
    "    scheduler = OneCycleLR(optimizer, max_lr=1e-3, steps_per_epoch=len(loaders['train']), epochs=n_epochs)\n",
    "        \n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        # initialize variables to monitor training and validation loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        \n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            ## find the loss and update the model parameters accordingly\n",
    "            ## record the average training loss, using something like\n",
    "            ## train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
    "            scheduler.step()\n",
    "            if batch_idx + 1 == len(loaders['train']):\n",
    "                print(scheduler.get_last_lr())\n",
    "            \n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "        model.eval()\n",
    "        for batch_idx, (data, target) in enumerate(loaders['valid']):\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            ## update the average validation loss\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, target)\n",
    "            valid_loss += ((1 / (batch_idx + 1)) * (loss.data - valid_loss))\n",
    "            \n",
    "        # print training/validation statistics \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "            epoch, \n",
    "            train_loss,\n",
    "            valid_loss\n",
    "            ))\n",
    "        \n",
    "        ## TODO: save the model if validation loss has decreased\n",
    "        if valid_loss < valid_loss_min:\n",
    "            early_stopping_patience = 5\n",
    "            print(f'Validation loss decreased ({valid_loss_min} --> {valid_loss}).  Saving model ...')\n",
    "            torch.save(model, save_path)\n",
    "            valid_loss_min = valid_loss\n",
    "        else:\n",
    "            early_stopping_patience -= 1\n",
    "            if not early_stopping_patience:\n",
    "                print(f'Early stopping...')\n",
    "                break\n",
    "    # return trained model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = 'dog_classification_model_v2.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.262990431259093e-05]\n",
      "Epoch: 1 \tTraining Loss: 4.896869 \tValidation Loss: 4.654789\n",
      "Validation loss decreased (inf --> 4.654788970947266).  Saving model ...\n",
      "[5.0490798930807944e-05]\n",
      "Epoch: 2 \tTraining Loss: 4.614444 \tValidation Loss: 4.357718\n",
      "Validation loss decreased (4.654788970947266 --> 4.357717990875244).  Saving model ...\n",
      "[6.34965446852456e-05]\n",
      "Epoch: 3 \tTraining Loss: 4.341475 \tValidation Loss: 4.022571\n",
      "Validation loss decreased (4.357717990875244 --> 4.022570610046387).  Saving model ...\n",
      "[8.150462546403715e-05]\n",
      "Epoch: 4 \tTraining Loss: 4.023089 \tValidation Loss: 3.671246\n",
      "Validation loss decreased (4.022570610046387 --> 3.67124605178833).  Saving model ...\n",
      "[0.0001043177098950924]\n",
      "Epoch: 5 \tTraining Loss: 3.662005 \tValidation Loss: 3.265269\n",
      "Validation loss decreased (3.67124605178833 --> 3.265268564224243).  Saving model ...\n",
      "[0.00013168581369037515]\n",
      "Epoch: 6 \tTraining Loss: 3.315217 \tValidation Loss: 2.851897\n",
      "Validation loss decreased (3.265268564224243 --> 2.8518970012664795).  Saving model ...\n",
      "[0.00016330903895739064]\n",
      "Epoch: 7 \tTraining Loss: 2.942384 \tValidation Loss: 2.507902\n",
      "Validation loss decreased (2.8518970012664795 --> 2.507901668548584).  Saving model ...\n",
      "[0.00019884086046069015]\n",
      "Epoch: 8 \tTraining Loss: 2.591007 \tValidation Loss: 2.160992\n",
      "Validation loss decreased (2.507901668548584 --> 2.16099214553833).  Saving model ...\n",
      "[0.00023789192282274991]\n",
      "Epoch: 9 \tTraining Loss: 2.291238 \tValidation Loss: 1.856583\n",
      "Validation loss decreased (2.16099214553833 --> 1.8565828800201416).  Saving model ...\n",
      "[0.0002800343070547478]\n",
      "Epoch: 10 \tTraining Loss: 2.020065 \tValidation Loss: 1.636232\n",
      "Validation loss decreased (1.8565828800201416 --> 1.6362323760986328).  Saving model ...\n",
      "[0.00032480621966487306]\n",
      "Epoch: 11 \tTraining Loss: 1.804959 \tValidation Loss: 1.451405\n",
      "Validation loss decreased (1.6362323760986328 --> 1.4514051675796509).  Saving model ...\n",
      "[0.0003717170529612245]\n",
      "Epoch: 12 \tTraining Loss: 1.622618 \tValidation Loss: 1.289154\n",
      "Validation loss decreased (1.4514051675796509 --> 1.289153814315796).  Saving model ...\n",
      "[0.00042025276109883]\n",
      "Epoch: 13 \tTraining Loss: 1.480256 \tValidation Loss: 1.184551\n",
      "Validation loss decreased (1.289153814315796 --> 1.1845513582229614).  Saving model ...\n",
      "[0.00046988149296041555]\n",
      "Epoch: 14 \tTraining Loss: 1.342536 \tValidation Loss: 1.095938\n",
      "Validation loss decreased (1.1845513582229614 --> 1.0959380865097046).  Saving model ...\n",
      "[0.0005200594201461846]\n",
      "Epoch: 15 \tTraining Loss: 1.251008 \tValidation Loss: 1.003132\n",
      "Validation loss decreased (1.0959380865097046 --> 1.0031323432922363).  Saving model ...\n",
      "[0.0005702366962098756]\n",
      "Epoch: 16 \tTraining Loss: 1.141057 \tValidation Loss: 0.933751\n",
      "Validation loss decreased (1.0031323432922363 --> 0.9337509274482727).  Saving model ...\n",
      "[0.0006198634818401805]\n",
      "Epoch: 17 \tTraining Loss: 1.087135 \tValidation Loss: 0.888085\n",
      "Validation loss decreased (0.9337509274482727 --> 0.8880850076675415).  Saving model ...\n",
      "[0.0006683959699639777]\n",
      "Epoch: 18 \tTraining Loss: 1.031716 \tValidation Loss: 0.838455\n",
      "Validation loss decreased (0.8880850076675415 --> 0.838455319404602).  Saving model ...\n",
      "[0.0007153023447486943]\n",
      "Epoch: 19 \tTraining Loss: 0.978818 \tValidation Loss: 0.805067\n",
      "Validation loss decreased (0.838455319404602 --> 0.805067241191864).  Saving model ...\n",
      "[0.0007600686092054372]\n",
      "Epoch: 20 \tTraining Loss: 0.916746 \tValidation Loss: 0.763008\n",
      "Validation loss decreased (0.805067241191864 --> 0.7630083560943604).  Saving model ...\n",
      "[0.0008022042175344003]\n",
      "Epoch: 21 \tTraining Loss: 0.877113 \tValidation Loss: 0.734134\n",
      "Validation loss decreased (0.7630083560943604 --> 0.7341344952583313).  Saving model ...\n",
      "[0.0008412474504936758]\n",
      "Epoch: 22 \tTraining Loss: 0.846691 \tValidation Loss: 0.703974\n",
      "Validation loss decreased (0.7341344952583313 --> 0.7039744257926941).  Saving model ...\n",
      "[0.0008767704748885258]\n",
      "Epoch: 23 \tTraining Loss: 0.812270 \tValidation Loss: 0.681253\n",
      "Validation loss decreased (0.7039744257926941 --> 0.681252658367157).  Saving model ...\n",
      "[0.0009083840317395654]\n",
      "Epoch: 24 \tTraining Loss: 0.779516 \tValidation Loss: 0.669856\n",
      "Validation loss decreased (0.681252658367157 --> 0.669856071472168).  Saving model ...\n",
      "[0.0009357417017572163]\n",
      "Epoch: 25 \tTraining Loss: 0.752478 \tValidation Loss: 0.650722\n",
      "Validation loss decreased (0.669856071472168 --> 0.6507221460342407).  Saving model ...\n",
      "[0.0009585437013816372]\n",
      "Epoch: 26 \tTraining Loss: 0.726399 \tValidation Loss: 0.628635\n",
      "Validation loss decreased (0.6507221460342407 --> 0.6286347508430481).  Saving model ...\n",
      "[0.0009765401677913783]\n",
      "Epoch: 27 \tTraining Loss: 0.707307 \tValidation Loss: 0.627755\n",
      "Validation loss decreased (0.6286347508430481 --> 0.6277549862861633).  Saving model ...\n",
      "[0.0009895338968838464]\n",
      "Epoch: 28 \tTraining Loss: 0.693741 \tValidation Loss: 0.607645\n",
      "Validation loss decreased (0.6277549862861633 --> 0.6076452136039734).  Saving model ...\n",
      "[0.000997382504224971]\n",
      "Epoch: 29 \tTraining Loss: 0.672416 \tValidation Loss: 0.609702\n",
      "[0.0009999999971857596]\n",
      "Epoch: 30 \tTraining Loss: 0.657355 \tValidation Loss: 0.598447\n",
      "Validation loss decreased (0.6076452136039734 --> 0.598447322845459).  Saving model ...\n",
      "[0.0009994941524248673]\n",
      "Epoch: 31 \tTraining Loss: 0.628053 \tValidation Loss: 0.592685\n",
      "Validation loss decreased (0.598447322845459 --> 0.592685341835022).  Saving model ...\n",
      "[0.0009979823969427204]\n",
      "Epoch: 32 \tTraining Loss: 0.627257 \tValidation Loss: 0.579399\n",
      "Validation loss decreased (0.592685341835022 --> 0.5793989896774292).  Saving model ...\n",
      "[0.0009954677752136711]\n",
      "Epoch: 33 \tTraining Loss: 0.605429 \tValidation Loss: 0.572389\n",
      "Validation loss decreased (0.5793989896774292 --> 0.572388768196106).  Saving model ...\n",
      "[0.0009919553513512299]\n",
      "Epoch: 34 \tTraining Loss: 0.595098 \tValidation Loss: 0.555414\n",
      "Validation loss decreased (0.572388768196106 --> 0.5554139614105225).  Saving model ...\n",
      "[0.0009874521989096127]\n",
      "Epoch: 35 \tTraining Loss: 0.593125 \tValidation Loss: 0.559481\n",
      "[0.0009819673866385457]\n",
      "Epoch: 36 \tTraining Loss: 0.578042 \tValidation Loss: 0.553915\n",
      "Validation loss decreased (0.5554139614105225 --> 0.5539154410362244).  Saving model ...\n",
      "[0.0009755119602200093]\n",
      "Epoch: 37 \tTraining Loss: 0.565689 \tValidation Loss: 0.545408\n",
      "Validation loss decreased (0.5539154410362244 --> 0.5454076528549194).  Saving model ...\n",
      "[0.0009680989200237058]\n",
      "Epoch: 38 \tTraining Loss: 0.561583 \tValidation Loss: 0.564166\n",
      "[0.0009597431949260434]\n",
      "Epoch: 39 \tTraining Loss: 0.539340 \tValidation Loss: 0.546989\n",
      "[0.000950461612245367]\n",
      "Epoch: 40 \tTraining Loss: 0.534760 \tValidation Loss: 0.539934\n",
      "Validation loss decreased (0.5454076528549194 --> 0.5399340391159058).  Saving model ...\n",
      "[0.0009402728638539779]\n",
      "Epoch: 41 \tTraining Loss: 0.532895 \tValidation Loss: 0.530556\n",
      "Validation loss decreased (0.5399340391159058 --> 0.5305555462837219).  Saving model ...\n",
      "[0.0009291974685351911]\n",
      "Epoch: 42 \tTraining Loss: 0.534053 \tValidation Loss: 0.532570\n",
      "[0.000917257730661236]\n",
      "Epoch: 43 \tTraining Loss: 0.516750 \tValidation Loss: 0.531878\n",
      "[0.0009044776952752188]\n",
      "Epoch: 44 \tTraining Loss: 0.514285 \tValidation Loss: 0.519950\n",
      "Validation loss decreased (0.5305555462837219 --> 0.5199499726295471).  Saving model ...\n",
      "[0.0008908830996676063]\n",
      "Epoch: 45 \tTraining Loss: 0.503050 \tValidation Loss: 0.518140\n",
      "Validation loss decreased (0.5199499726295471 --> 0.5181397795677185).  Saving model ...\n",
      "[0.0008765013215447477]\n",
      "Epoch: 46 \tTraining Loss: 0.505459 \tValidation Loss: 0.513223\n",
      "Validation loss decreased (0.5181397795677185 --> 0.51322340965271).  Saving model ...\n",
      "[0.0008613613238938176]\n",
      "Epoch: 47 \tTraining Loss: 0.485260 \tValidation Loss: 0.513895\n",
      "[0.0008454935966552144]\n",
      "Epoch: 48 \tTraining Loss: 0.486068 \tValidation Loss: 0.521948\n",
      "[0.0008289300953198776]\n",
      "Epoch: 49 \tTraining Loss: 0.469632 \tValidation Loss: 0.513270\n",
      "[0.0008117041765751824]\n",
      "Epoch: 50 \tTraining Loss: 0.480901 \tValidation Loss: 0.512502\n",
      "Validation loss decreased (0.51322340965271 --> 0.5125022530555725).  Saving model ...\n",
      "[0.0007938505311290099]\n",
      "Epoch: 51 \tTraining Loss: 0.468056 \tValidation Loss: 0.505163\n",
      "Validation loss decreased (0.5125022530555725 --> 0.5051627159118652).  Saving model ...\n",
      "[0.0007754051138472788]\n",
      "Epoch: 52 \tTraining Loss: 0.455751 \tValidation Loss: 0.493719\n",
      "Validation loss decreased (0.5051627159118652 --> 0.49371907114982605).  Saving model ...\n",
      "[0.0007564050713456298]\n",
      "Epoch: 53 \tTraining Loss: 0.456011 \tValidation Loss: 0.497530\n",
      "[0.0007368886671810857]\n",
      "Epoch: 54 \tTraining Loss: 0.460863 \tValidation Loss: 0.504425\n",
      "[0.0007168952047943392]\n",
      "Epoch: 55 \tTraining Loss: 0.455325 \tValidation Loss: 0.500527\n",
      "[0.000696464948357855]\n",
      "Epoch: 56 \tTraining Loss: 0.451241 \tValidation Loss: 0.498793\n",
      "[0.0006756390416891836]\n",
      "Epoch: 57 \tTraining Loss: 0.438319 \tValidation Loss: 0.487819\n",
      "Validation loss decreased (0.49371907114982605 --> 0.4878194034099579).  Saving model ...\n",
      "[0.0006544594253927897]\n",
      "Epoch: 58 \tTraining Loss: 0.453196 \tValidation Loss: 0.510180\n",
      "[0.0006329687523972549]\n",
      "Epoch: 59 \tTraining Loss: 0.442204 \tValidation Loss: 0.491131\n",
      "[0.0006112103020579571]\n",
      "Epoch: 60 \tTraining Loss: 0.421944 \tValidation Loss: 0.483126\n",
      "Validation loss decreased (0.4878194034099579 --> 0.48312607407569885).  Saving model ...\n",
      "[0.0005892278929982078]\n",
      "Epoch: 61 \tTraining Loss: 0.422829 \tValidation Loss: 0.491000\n",
      "[0.0005670657948643766]\n",
      "Epoch: 62 \tTraining Loss: 0.425455 \tValidation Loss: 0.485758\n",
      "[0.0005447686391727147]\n",
      "Epoch: 63 \tTraining Loss: 0.424163 \tValidation Loss: 0.484319\n",
      "[0.0005223813294274209]\n",
      "Epoch: 64 \tTraining Loss: 0.412286 \tValidation Loss: 0.484922\n",
      "[0.0004999489506909604]\n",
      "Epoch: 65 \tTraining Loss: 0.412383 \tValidation Loss: 0.485015\n",
      "Early stopping...\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "model_transfer = train(n_epochs, loaders_transfer, model_transfer, optimizer_transfer, criterion_transfer, use_cuda, model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loaders, model, criterion, use_cuda):\n",
    "    # monitor test loss and accuracy\n",
    "    test_loss = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "\n",
    "    model.eval()\n",
    "    for batch_idx, (data, target) in enumerate(loaders['test']):\n",
    "        # move to GPU\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        # update average test loss \n",
    "        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
    "        # convert output probabilities to predicted class\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        # compare predictions to true label\n",
    "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
    "        total += data.size(0)\n",
    "            \n",
    "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n",
    "        100. * correct / total, correct, total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test = torch.load(model_file, map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.503747\n",
      "\n",
      "\n",
      "Test Accuracy: 85% (716/836)\n"
     ]
    }
   ],
   "source": [
    "criterion_transfer = nn.CrossEntropyLoss()\n",
    "test(loaders_transfer, model_test, criterion_transfer, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m48",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m48"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
